\title{
Nonlinear Trading Rules for Portfolio Management ${ }^{1}$
}

\footnotetext{
1. This chapter originally appeared as "Non-Linear Trading Rules for Portfolio Management" by Richard Grinold in the Journal of Portfolio Management, Fall 2018, 62-70.
}

In "Linear Trading Rules for Portfolio Management," Grinold (2018) and Chapter 10 in this book, we addressed the challenge of dynamic portfolio management. We showed how an optimized dynamic policy called a linear trading rule (LTR) could be used to manage portfolios on an asset-by-asset basis. We also described how the information gained from the study of LTRs could be folded into a single-stage, multi-asset optimization that also considers factor positions, factor and sector risk, and constraints. We, in effect, harness the static optimization to implement the dynamic policy.

LTRs are optimal in special circumstances and should be a good starting point in more general circumstances. LTRs are also attractive because they come with a theory that provides analytic expressions for key expected attributes of a strategy: the alpha, risk, and transactions cost ( t -cost), conditional on the single parameter that determines the LTR.

This article takes the concept further by introducing nonlinear trading rules (henceforth NLTRs). The NLTRs are also motivated by theory. However, they do not lead to formulas for expected alpha, risk, and t -cost. Instead, we rely on simulation to assess the expected performance using any rule. It is heavy-handed but it works.

Despite the technical nature of the material we have tried to keep the equations and related quant jargon to a minimum. The Appendices look at some of the technical aspects in more detail.



NLTRs are built on the foundation of the LTRs. A review of LTRs will introduce the notation and terminology used throughout. After this review of LTRs, we consider a motivational example for one asset and one period. This simple example provides the form of the NLTR (Exhibit 1).

**EXHIBIT 1** The Nonlinear Trading Rule
![](https://cdn.mathpix.com/cropped/2025_02_04_7ee054479266d0d6841bg-256.jpg?height=922&width=1144&top_left_y=365&top_left_x=177)

Thus encouraged, we set out to determine the best NLTR for each asset.
The first step is to describe and then validate the simulation/optimization approach. We can do this using LTRs since they, as mentioned above, are accompanied by analytic expressions for key performance measures (alpha, risk, t -cost). This allows us to check simulation results against the analytical results.

Step two is to establish a benchmark. To that end we introduce a quasi-dynamic version of one-stage optimization that we call TCAF. The benchmark is the best TCAF policy. There are now three policy choices in the mix: TCAF, LTR, and NLTR. We select the best policy in each class and compare the results.

Forecasts of future return are derived from a collection of signals, which are represented by standardized random variables with mean zero and standard deviation one. The signals are assumed to contain information about future return. The goal of the active portfolio manager is to obtain the most cost- and risk-effective exposures to the signals.

With the framework established, we test the process on a problem that is complicated enough to illustrate the concept and simple enough to be understood with a small amount of effort. The examples have three uncorrelated signals for each asset. The goal is to illustrate the methodology, not to swamp the reader in output. The technique is scalable. It has been used with up to 32 signals per asset and with significant correlations among the signals.

There are two reasonable measures of aggregate performance. The first is the form of a typical optimization criterion:
$$
\text { Objective } \equiv\{\text { Alpha }\}-\frac{\lambda}{2} \cdot\{\text { Risk }\}^{2}-\{\text { T-Cost }\}
$$

In our case, all three quantities are expressed as annual rates; for example, T-Cost is the total transactions cost incurred for all assets over all periods divided by the number of years in the simulation.

The second measure is the after cost information ratio (ACIR):
$$
\left\{\begin{array}{c}
\text { After Cost } \\
\text { Information Ratio }
\end{array}\right\}=\frac{\{\text { Alpha }\}-\{\text { T-Cost }\}}{\{\text { Risk }\}}
$$

If the risk levels of two strategies are the same, then the two measures will select the same winner in a two-strategy race. If the risk levels differ, then the ACIR is attractive for comparison, since its numerator tells us the expected performance and the ACIR itself provides an estimate of the probability of a negative year. ${ }^{2}$ We will concentrate on the ACIR and try to keep the risk levels relatively close when comparing strategies. In the discussion to follow, benefit means annual Alpha minus $T$-Cost over the simulation (i.e., the numerator of the ACIR).

For our universe of 3,136 US assets the best LTR policy outperforms TCAF by $0.42 \%$ per year and the NLTR outperforms the LTR by $0.60 \%$ per year, making a net gain over TCAF of $1.02 \%$ per year. However, things didn't turn out quite so well in our universe of 200 Australian assets. The dynamic LTR policy adds $0.66 \%$ per year compared to the static TCAF policy, but the NLTR yield a disappointing $0.05 \%$ more per year as compared to the LTR, with a net gain of $0.71 \%$ per year over TCAF. ${ }^{3}$

In addition to the NLTRs performance, another benefit is restrained trading. An LTR will suggest a trade in each period for each asset-a potential operational nightmare. The typical NLTR used in our results trades $28 \%$ of the time, although the trades, when they do occur, are on average about three times larger.

\footnotetext{
2. If the ACIR equals 0.75 and the active returns minus $t$-cost are normal, then $\operatorname{Prob}(Z<-0.75)=0.23$ gives us the probability of a down year even if our alpha forecasts are as good as we assumed they are.
3. The Australian t -cost model is a linear plus a quadratic term, for example Equation (6). In this case, the LTR model gives the optimal solution if the linear $t$-cost term is zero and should be close to optimal when the linear $t$-cost term is small. As a test, we multiplied the linear $t$-cost coefficient by 5 and solved again. Indeed, we saw a benefit of about $0.40 \%$ using the NLTR in that case.
}

The approach is restricted to predictions of specific asset return. This allows us to consider each asset in isolation. ${ }^{4}$ We do not consider factor returns, smart beta tilts, industry timing, or sector returns, although the NLTR can be integrated with a larger process that does consider those aggregate aspects. Aside from the limitation to a single asset, the approach is general. It will work with any number of signals. We need to know about the strength (forecasting potential) of the signal and the nature of the process generating the signal. That process can be smooth, can have jumps, or can allow for different rates of information flow at different points in the year. It must be mean reverting, reflecting the fact that old information eventually loses its value and new information arrives, randomly, to replace it. Otherwise, if you can specify it, you can use it.

There is considerable literature on the topic of portfolio optimization with transactions costs. ${ }^{5}$ Most of the theoretical work uses linear (proportional) transactions cost, although Grinold (2018) (Chapter 10 in this book) and Garleanu and Pederson (2009) consider quadratic transactions cost with no proportional (linear) cost. We will follow industry practice and the LTR paper and consider the case with both proportional cost and significant nonlinear costs due to market impact. The unique perspective in this and the LTR article is restricting attention to policies with a specified structure and limiting attention to a single asset. This allows us to obtain good solutions to an otherwise intractable stochastic dynamic programming problem. ${ }^{6}$ For more on the simulation/optimization approach, see Powell (2011).

\footnotetext{
4. In practice, this means we either ignore any significant correlation of signals across assets or find other way to incorporate that information. This is discussed in Grinold (2018), on "Linear Trading Rules for Portfolio Management," Chapter 10 in this book.
5. See Boyd et al (2017) for current practice in portfolio optimization, along with an extensive bibliography.
6. We came to the simulation/optimization approach in a roundabout manner. The LTR parameters could be selected analytically. We used a simulation to demonstrate that the analytic predictions were accurate. They were. Next, we asked if we could choose the trade rate parameter using the simulation, and would it be near the analytic value? We could, and it was. Then the penny dropped, and we cast about for references.
}

\section*{Zero Cost and Target Signal Weights}

The following results are available in Chapter 10 on LTRs and its technical appendices. The terminology is from Grinold and Kahn (2000).

There are $J$ signals whose forecasting ability is measured by the correlation of the signal with the return. This correlation is called the information coefficient. From this information, we can calculate the weights on the signals one would use with no transactions costs. These weights, called the zero-cost weights, are denoted $w_{\mathcal{Q}(n) ;}$ for asset $n$ and signal $j$. In most of what follows, we will drop the notation $n$ referring to asset $n$. The reader gets the benefit of cleaner notation and the attendant obligation to remember that all the results are asset specific.

The zero-cost weights $w_{Q, j}$ are determined by the assumed information coefficients, any correlation among the signals, and a risk penalty parameter. Equation (1) shows the calculation. ${ }^{7}$
$\iota_{j} \quad$ the information coefficient for signal $j$
$\sigma \quad$ specific risk
$\lambda \quad$ a penalty for risk
$R_{j, k} \quad$ the correlation between signals $j$ and $k$
$w_{\mathrm{Q}, j}$ the zero-cost weight on signal $j$
$\iota_{k}=\lambda \cdot \sigma \cdot \sum_{j=1: J} R_{K, j} \cdot w_{Q, j}, J$ equations to be solved for $w_{Q, j}$
The zero-cost weights play two roles. The first is the calculation of alpha, as per Equation (2):
$$
\begin{align*}
& \alpha(t)=\lambda \cdot \sigma^{2} \cdot q(t) \text { where } \\
& q(t)=\sum_{j=1: J} s_{j}(t) \cdot w_{\mathrm{Q}, j} \tag{2}
\end{align*}
$$

\footnotetext{
7. Grinold (2018) (Chapter 10, "Linear Trading Rules for Portfolio Management" in this book) used a top-down approach to the weighting question in contrast to the bottom-up approach we take here. The Appendix shows how the two approaches are equivalent, subject to certain assumptions.
}

The second role for the zero-cost weights is to serve as the foundation in the calculation of the target weights. Both the LTR and NLTR attempt to track a target (or model) position, denoted $m(t)$. The target is determined by a set of weights, $w_{M, j}$. We will take some time to show how these target/model weights are calculated since they are at the heart of the process.

The target weights determine the position that we should hold absent transactions cost on our next trade. In contrast, the zero-cost weights, $w_{\mathrm{Q}, i}$, determine the position we should hold absent transactions cost in the next period and all subsequent periods.

The target weights, $w_{M, j}$, are a discounted version of the zero-cost weights that take into consideration both the rate at which we trade and the rate at which the signals' information gets stale. A description of the target weights requires the notation in Equation (3) and a review of the LTR. As a reminder, the results in Equations (1) to (4), with the exception of the risk penalty $\lambda$, are asset specific.
$s_{j}(t) \quad$ the value of signal $j$ at time $t$
$m(t) \quad$ the target position at time $t$
$w_{M, j} \quad$ the target weights, to be determined
$m(t)=\sum_{j=1: J} s_{j}(t) \cdot w_{M, j}$
$\Delta t \quad$ the length of a trading period
$p(t-\Delta t)$ the initial, pre-trade, position
$p(t)$ the final, post-trade, position
$\Delta p(t) \quad$ the trade, $p(t)-p(t-\Delta t)$

The LTR depends on a positive trading rate $d_{\ell}$ with the $\ell$ standing for linear. The resulting LTR is described in Equation (4):
$$
\begin{align*}
& \delta_{\ell} \equiv e^{-d_{\ell} \cdot \Delta t} \text { is the retention fraction } \\
& \Delta p(t)=\left(1-\delta_{\ell}\right) \cdot\{m(t)-p(t-\Delta t)\}  \tag{4}\\
& \frac{\Delta p(t)}{\Delta t} \approx d_{\ell} \cdot\{m(t)-p(t)\} \text { for } \Delta t \text { small }
\end{align*}
$$

The LTR paper shows how to make an optimal choice of $d_{\ell}$ hence $\delta_{\ell}$.
The third item that influences the target weights is the rate at which information loses its forecasting ability, as measured by the half-lives of the signals.
$$
\begin{align*}
& H L_{j} \quad \text { the half-life of signal } j \text { in years } \\
& e^{-g_{j} \cdot H L_{j}}=0.5 \Rightarrow g_{j}=\ln (2) / H L_{j}, \text { decay rate }  \tag{5}\\
& \gamma_{j} \equiv e^{-g_{j} \cdot \Delta t} \text { signal retained in one period }
\end{align*}
$$

The formula for $w_{M, i}$, developed in the LTR paper, combines these three things-the zero-cost weights $w_{Q, j}$, the trading policy, $\delta_{\ell}$, and the decay of information, $\gamma_{j}$-to calculate the target weights:
$$
\begin{equation*}
w_{M, j}=\left\{\frac{1-\delta_{\ell}}{1-\delta_{\ell} \cdot \gamma_{j}}\right\} \cdot w_{Q, j} \text { the target signal weights } \tag{6}
\end{equation*}
$$

These are the weights used throughout the paper to determine the target position as per Equation (3). Again, note that both $\delta_{\ell}$ and $w_{Q, j}$ are asset specific, and the set of signals could be asset specific as well.

Exhibit 2 contains an example of the signal weight calculation and introduces the three signals used in our illustrative calculations. The numbers in Exhibit 2 are for a universe of 3,136 US stocks and an asset with median volatility and transactions cost. We use 252 trading days per year, so $\Delta t=1 / 252$. Note the steep discount in the weight of the FAST signal: the target weight is $4 \%$ of the zero-cost weight. Things are not so drastic for the SLOW signal where the discounted target weight is $76 \%$ of the zero-cost weight.

**EXHIBIT 2** The Signals and Typical Weights
\begin{tabular}{|l|r|r|r|c|}
\hline \multicolumn{1}{|c|}{ SIGNAL } & \multicolumn{1}{c|}{ IC } & HL (years) & \multicolumn{1}{c|}{ w_Q } & w_M \\
\hline FAST & 0.179 & $2 / 252$ & 0.04790 & 0.00188 \\
\hline INT. & 0.036 & $63 / 252$ & 0.00951 & 0.00497 \\
\hline SLOW & 0.020 & $189 / 252$ & 0.00540 & 0.00415 \\
\hline
\end{tabular}

The three-signal framework is for illustration only. The technique is scalable. We have solved problems with up to 32 signals per asset and with some significant correlations among the signals. See Grinold (2018), Chapter 10 in this book, for a discussion of natural limitations on signal correlation.

\section*{Motivation: A Single-Period Model}

The form of the NLTR policy comes from an examination of a one-period problem where the objective is to minimize a penalty for being off target plus the transactions cost due to a change in position. Since this is a one-period problem, we'll drop the time notation and let $p_{0}$ represent the initial position. The risk penalty is $\lambda$, the asset's specific volatility is $\sigma$, and the target position is denoted $m$.
$$
\begin{align*}
& \kappa\left(\Delta p \mid m, p_{0}\right) \quad \text { the penalty for being off target } \\
& \kappa\left(\Delta p \mid m, p_{0}\right) \equiv \frac{\lambda \cdot \sigma^{2}}{2} \cdot\left\{m-\left(p_{0}+\Delta p\right)\right\}^{2} \\
& \quad \text { the transactions cost }  \tag{7}\\
& c(\Delta p) \quad \\
& c(\Delta p) \equiv c_{1} \cdot|\Delta p|+\frac{c_{2}}{2} \cdot|\Delta p|^{2} \\
& \kappa\left(\Delta p \mid m, p_{0}\right)+c(\Delta p) \text { The objective }
\end{align*}
$$

The goal is to track the target while keeping transactions costs under control. ${ }^{8}$

\footnotetext{
8. This expression could be rewritten in the traditional form of an alpha minus a penalty for risk and any transactions cost. However, the alpha in that expression would then be confused with the actual alpha of Equation (2). A penalty for being off track seemed less confusing.
}

If are fortunate enough to start on target $\left(p_{0}=m\right)$, then the best decision is stay put $(\Delta p=0)$. If the starting position is below target $\left(p_{0}<m\right)$, the question is how much to buy, if any. When we start above target $\left(m<p_{0}\right)$, we ask how much, if any, to sell. The driver of the decision is the initial deviation from target. That deviation is called the backlog as it represents the amount of trading required to get on target.

We leave to the reader to check that that Equation (8) provides the optimal policy:
$$
\begin{aligned}
& b \equiv m-p_{0} \text { the backlog } \\
& z \equiv \frac{c_{1}}{\lambda \cdot \sigma^{2}} \text { is the size of the no trade zone } \\
& \delta \equiv \frac{c_{2}}{\lambda \cdot \sigma^{2}+c_{2}} \text { fraction of the initial position that is retained } \\
& \Delta p=\left\{\begin{array}{ccc}
(1-\delta) \cdot(b-z) \text { if } b>z & \text { BUY } \\
0 & \text { if }-z \leq b \leq z & \text { HOLD } \\
(1-\delta) \cdot(b+z) & \text { if } b<-z \text { SELL }
\end{array}\right\} \text { the NLTR }
\end{aligned}
$$

In Exhibit 1 above, the slope of the lines is $(1-\delta) \leq 1$. The flat part of the curve is the no-trade zone. Two special cases are worth noting: first, the NLTR includes the LTR as a special case (i.e., with $c_{1}=0$ we get $z=0$ ); second, in the case where there is no nonlinear term in the transactions cost ( $c_{2}=0$ ), we get $\delta=0$, and the optimal policy is stay put or move to the closest edge of the no-trade zone because $c_{2}=0$ means the slope of the NLTR line is one.

Equation (7) provides the template. The remaining task is to find the best values of the parameters $(\delta, z)$ for each asset. ${ }^{9}$

\footnotetext{
9. This motivating discussion is based on the form of transactions cost in Equation (7). For our US assets the nonlinear cost term increases with the $3 / 2$ power, not the square. See Appendix C for an argument boosting the NLTR form in Equation (8) as an approximation when the $3 / 2$ power rule is used.
}

\section*{Simulation/Optimization ${ }^{10}$}

We use a simulation and optimization process (sim/opt) to select the NLTR parameters, $(\delta, z)$. We are tuning the implementation engine for future use conditional on assumed signal strength and behavior. We are not evaluating past signal performance.

The sim/opt algorithm for any asset is:
1. Compute the best LTR, $\delta_{\ell}$, using the analytical results presented in the LTR article.
2. Compute the target weights, $w_{M, i}$, using the process described in Equations (3) through (5).
3. Simulate the signals $s_{j}(t)$ for $j=1: J$ and $t=0: T$. This, combined with the signal weights, provides the time series of target values, $m(t)$ as per Equation (3).
4. Choose a time-zero position, $p(0)$. This can, with no loss in accuracy if $T$ is large, be on target, $p(0)=m(0)$; if you are a purist, you can use the more elaborate process detailed in the LTR article. ${ }^{11}$
5. Systematically explore the space of possible trading rules and select the one with the highest annualized risk-adjusted alpha less transactions cost.

This process works.


\footnotetext{
10. We were tempted to call this front testing to emphasize that it has nothing to do with backtesting, a process that can generate more noise than insight.
11. Under an LTR the position, $p(t)$, at any time can be represented as a linear mix of the signals with a third set of weights, $w_{P}$, determining the mix plus a residual that is uncorrelated with the signals. Both $w_{p}$ and the standard deviation of the residual are known, so it is straightforward to generate a time-zero position conditional on the initial value of the signals plus a random residual.
}

\section*{Validation}

To validate the approach, we compared the results from Chapter 10 on linear trading rules and the sim/opt algorithm detailed above with the no-trade zone set to zero, that is $\mathrm{z}=0$ in Equation (8). When the no-trade zone is zero, we can calculate the optimal trade parameter without resort to simulation. Solving the same problem with the sim/opt approach gives a direct comparison.


The results are in Exhibit 3. We used a sample of 3,136 US stocks. The risk penalty parameter was $\lambda=22$. The transactions cost are the $3 / 2$ power variety, and the signals had the properties described in Exhibit 2. The results are based on one rebalance each trading day, with 252 trading days per year and a 100-year simulation. These are aggregate, portfolio-level results. The three columns in Exhibit 3 are, respectively, THEORY where the optimal trade rate is selected analytically, IN SAMPLE, in which the trade rate is selected by the simulation/optimization algorithm described earlier and evaluated using the same sample, and OUT SAMPLE in which the trade rates selected by the sim/opt algorithm are evaluated on a new set of data.

EXHIBIT 3 Validation Results
\begin{tabular}{|l|c|c|c|}
\hline & THEORY & IN SAMPLE & OUT SAMPLE \\
\hline Alpha \% & 4.65 & 4.56 & 4.57 \\
\hline Risk \% & 3.32 & 3.27 & 3.29 \\
\hline T-Cost \$ & 2.10 & 2.06 & 2.12 \\
\hline Alpha - TC & 2.56 & 2.50 & 2.46 \\
\hline ACIR & 0.77 & 0.77 & 0.75 \\
\hline
\end{tabular}

The details of these calculations are in Appendix B.

\section*{TCAF: A Static Benchmark}

Equation (7) describes an objective that balances between a penalty for being off target and the cost for moving toward the target. The penalty for being off target is annualized, that is, it is the penalty for being a certain distance from target for a year, expressed as a loss in annual return. The transactions cost term represents a loss in return incurred at a point in time. Suppose, for the sake of argument, that the trade keeps us the same distance from the target for four months and then we go back to the initial situation. To get an apples-to-apples annual run-rate comparison, we must reinvest, that is, incur the t -cost again, at four months and again at eight months to stay at the same distance from target for the entire year. In this case the proper objective would be $\kappa\left(\Delta p \mid m, p_{0}\right)+3 \cdot c(\Delta p)$ because we have to pay the $t$-cost three times per year to keep up. If, on the other hand, the trade would keep us the same distance from target for two years, then $\kappa\left(\Delta p \mid m, p_{0}\right)+0.5 \cdot c(\Delta p)$ would be more appropriate. In general, we want to use the criterion:
$$
\begin{equation*}
\kappa\left(\Delta p \mid m, p_{0}\right)+\tau \cdot c(\Delta p) \tag{9}
\end{equation*}
$$
where $\tau$ is an amortization factor used to annualize the t -cost. ${ }^{12}$ The TCAF strategy uses the simulation/optimization algorithm to find the best value for the amortization factor $\tau$.

\footnotetext{
12. The choice is inescapable. Ignore it and you have selected $\tau=1$.
}

The TCAF strategy works as follows. The sim/opt procedure provides the time series values of the target, $m(t)$. We choose a value of $\tau$. Then we choose $\Delta p$ at each point in time using Equation (9) as a criterion. Finally, the performance of the resulting sequence of positions and trades is tallied up in the manner described in Appendix B. The value of $\tau$ that yields the best performance is selected as the TCAF policy parameter for that asset.

\section*{NLTR Results}

An LTR does better than the optimized single-stage benchmark TCAF. The NLTR is an improvement over the LTR in the larger universe of US stocks although it only a slight improvement in the smaller universe of 200 Australian assets. The aggregate US results are in Exhibit 4. The risk penalty was varied in each case to get the risk level approximately the same for each type of policy.

**EXHIBIT 4** Results for the 3,136 US Assets Using Three Different Policies
\begin{tabular}{|l|c|c|c|}
\hline \multicolumn{1}{|c|}{ USA } & TCAF & LTR & NLTR \\
\hline Alpha \% & 2.71 & 4.66 & 5.14 \\
\hline Risk \% & 3.27 & 3.32 & 3.21 \\
\hline T-Cost \% & 0.57 & 2.10 & 1.98 \\
\hline Alpha - TC & 2.14 & 2.56 & 3.16 \\
\hline ACIR & 0.66 & 0.77 & 0.98 \\
\hline
\end{tabular}

The LTR and NLTR rules lead to more trading. With the TCAF rule some 996 high transactions cost assets do not trade at all.

The results for the universe of 200 Australian assets are contained in Exhibit 5. Comparisons of the NLTR results using the sim/opt and model parameters for the United States and Australia are given in Exhibits 6 and 7.

**EXHIBIT 5** Results for 200 Australian Assets Using Three Different Policies
\begin{tabular}{|l|c|c|c|}
\hline \multicolumn{1}{|c|}{ AUS } & TCAF & LTR & NLTR \\
\hline Alpha \% & 4.86 & 6.65 & 6.66 \\
\hline Risk \% & 3.94 & 3.93 & 3.91 \\
\hline T-Cost \% & 0.66 & 1.79 & 1.75 \\
\hline Alpha - TC & 4.20 & 4.86 & 4.91 \\
\hline ACIR & 1.07 & 1.24 & 1.26 \\
\hline
\end{tabular}
$\lambda=19$ for TCAF and $\lambda=25$ for LTR and NLTR.

\section*{The Parameter Model}

The sim/opt procedure is a blunt instrument doing precision work. The choice of parameters $(\delta, z)$ is a delicate matter. For a typical asset the performance benefit of the optimal NLTR over the best policy with $z=0$ (i.e., the LTR) is about 2 or 3 basis points per century! Because this sensitive choice is based on simulated data, we should expect considerable noise in the chosen policy parameters. To mitigate the noise, we built a cross-sectional model for the parameters using a log-log regression framework.

Subscript $n$ refers to asset $n$
$$
\delta_{n}=e^{-d_{n} \cdot \Delta t} \Rightarrow d_{n}=-\ln \left(\delta_{n}\right) / \Delta t
$$

The Cross Sectional Regressions
$$
\begin{align*}
& \ln \left(d_{n}\right)=\beta_{1}+\beta_{2} \cdot \ln \left(c_{1, n}\right)+\beta_{3} \cdot \ln \left(c_{2, n}\right)+\beta_{4} \cdot \ln \left(\sigma_{n}\right)+\xi_{n}  \tag{10}\\
& \ln \left(z_{n}\right)=\phi_{1}+\phi_{2} \cdot \ln \left(c_{1, n}\right)+\phi_{3} \cdot \ln \left(c_{2, n}\right)+\phi_{4} \cdot \ln \left(\sigma_{n}\right)+\varsigma_{n}
\end{align*}
$$

The Fitted Values
$$
\hat{d}_{n}=d_{n} \cdot e^{-\xi_{n}}, \quad \hat{z}_{n}=z_{n} \cdot e^{-\varsigma_{n}}
$$

In Equation (10), $d_{n}, z_{n}$ are the parameters selected by the sim/opt algorithm. The idea is that the fitted values will filter the noise from sim/opt process without losing the essence of the NLTR. This turns out to be the case since a NLTR based on the fitted values $\left(\hat{d}_{n}, \hat{z}_{n}\right)$ performs just as well as the original parameters, with a lower cross-sectional variation in the parameter values.

The parameter model has the additional benefit of producing a NLTR for a new asset as long as we have $t$-cost and volatility estimates. In the same fashion, the parameter model can be used to update the trading rules, without resort to sim/opt, when an asset's t-cost and volatility estimates change. ${ }^{13}$

**EXHIBIT 6** Comparison of NLTR Results for the US Using the Sim/Opt Parameters and the Model Parameters
\begin{tabular}{|l|c|c|}
\hline \multicolumn{1}{|c|}{ USA } & NLTR & NLTR FIT \\
\hline Alpha \% & 5.14 & 5.19 \\
\hline Risk \% & 3.21 & 3.22 \\
\hline T-Cost \% & 1.98 & 2.05 \\
\hline Alpha - TC & 3.16 & 3.14 \\
\hline ACIR & 0.98 & 0.98 \\
\hline
\end{tabular}

\footnotetext{
13. There are more details on the parameter model in Appendix D.
}

**EXHIBIT 7** Comparison of NLTR Results for Australia Using the Sim/Opt Parameters and the Model Parameters
\begin{tabular}{|l|c|c|}
\hline \multicolumn{1}{|c|}{ AUS } & NLTR & NLTR FIT \\
\hline Alpha \% & 6.66 & 6.65 \\
\hline Risk \% & 3.91 & 1.93 \\
\hline T-Cost \% & 1.75 & 1.76 \\
\hline Alpha - TC & 4.91 & 4.90 \\
\hline ACIR & 1.26 & 1.25 \\
\hline
\end{tabular}

\section*{Implementation}

In the LTR chapter, we discussed at length how the information from an optimized LTR could be exploited to turn a single-stage portfolio optimizer into a dynamic optimizer. The same idea works with the NLTR. In this case, we associate a term for each asset that penalizes deviations from model position and a modified version of the transaction costs.

For each asset there is a penalty
$$
\begin{align*}
& \frac{\lambda \cdot \sigma^{2}}{2}\left(m-\left(p_{0}+\Delta p\right)\right)^{2}+\hat{c}(\Delta p) \\
& \text { where } \\
& m=\sum_{j=1: J} s_{j} \cdot w_{M, j} \text { is the target }  \tag{11}\\
& \hat{c}(\Delta p)=\hat{c}_{1} \cdot|\Delta p|+\frac{\hat{c}_{2}}{2} \cdot|\Delta p|^{2} \text { where } \\
& \hat{c}_{1}=\lambda \cdot \sigma^{2} \cdot z, \hat{c}_{2}=\lambda \cdot \sigma^{2} \cdot \frac{\delta}{1-\delta}
\end{align*}
$$

The first term is unchanged from Equation (7). It is a penalty for the deviation from target. The second term has been altered. The initial transactions $\operatorname{costs}\left(c_{1}, c_{2}\right)$ are gone, and instead the NLTR parameters are used to determine a modified t -cost. The original t -cost information is imbedded in the policy parameters. We use this form even if we started with a $3 / 2$ power transactions cost model.

\section*{Summary}

This chapter is a continuation of the chapter on linear trading rules. The essential notion in both is a dynamic view of the portfolio optimization challenge. In its full complexity, dynamic portfolio optimization is an
overwhelming task, at least with current technology and human capital. ${ }^{14}$ However, if we consider the assets one at a time and restrict ourselves to trading policies in a class, such as linear trading rules, or nonlinear trading rules, we gain entry into otherwise obscure space and can optimize the trading policy subject to retaining its form.

\footnotetext{
14. For example, with 2,000 assets, 19 signals, and one position per asset, the state space is $20 * 2,000=$ 40,000 real numbers. If you discretize with 10 discrete values along each dimension, then the dynamic programming state space is 10 to the 40,000 th power.
}

Additional key points are as follows:
- Signal weights and trading policy should be asset specific.
- The NLTR and LTR dynamic policies offer significant benefits when compared with an optimized static policy.
- The policy parameter model of Equation (10) is an essential part of the process, akin to a cabinet maker sanding the rough edges.

Aside from these specifics the most significant point is moving from a static mindset to a dynamic one when addressing the portfolio management challenge.

\section*{References}

Boyd, Stephen, Enzo Busseti, Stephen Diamond, Ronald N. Kahn, Kwangmoo Koh, P. Nystrup, and Jan Speth. 2017. "Multi-Period Trading via Convex Optimization." Foundations and Trends in Optimization 3 (1): 1-76.

Garleanu, Nicolae, and Lasse Pedersen. 2009. "Dynamic Trading with Predictable Returns and Transactions Costs." NBER Working Paper \# 15205, revised 2013.
Grinold, Richard. "Linear Trading Rules for Portfolio Management." 2018. Journal of Portfolio Management 44 (6), Special Stephen Ross Issue, 109-19.
Grinold, Richard, and Ronald N. Kahn. 2000. Active Portfolio Management. 2nd ed. New York: McGraw Hill.
Powell, William B. 2011. Approximate Dynamic Programming: Solving the Curses of Dimensionality. 2nd ed. Wiley Series in Probability and Statistics. Hoboken: Wiley.

