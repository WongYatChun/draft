\title{Chapter 13: Dynamic Risk Allocation}

\section*{Inroduction}

**Questions**
1. How should we allocate risk to our strategy over time?
2. How is intertemporal risk allocation related to single-period portfolio optimization?
3. How do control the risk of large drawdowns over time?

So far we have focused exclusively on single-period portfolio optimization. This may be appropriate for one-off investment decisions, but is inadequate for long-term investment strategies. There is a rich academic literature on inter-temporal choice theory, which aims at modeling the interplay between consumption and investment in the long run, both at the level of the individual consumer and at the aggregate level. Much of the literature has been ignored by asset managers for their investment decisions, for reasons we conjecture below. First, these models require the specification of a principled utility function and of an inter-temporal tradeoff (in the form of a discount factor for future utility), something that no investment manager would or could specify. If quadratic utility had been the main justification of mean-variance optimization, it would probably have never been adopted. Secondly, these models don't capture well
the institutional setting of asset managers. "Consumption" for asset managers corresponds to outflows, and asset managers don't receive any utility from it. Moreover, outflows do not bear a direct relationship to the principals' utilities (i.e., those who provide the investment capital to the managers). The reason for this is that inflows and outflows occur at low rates (they are "sticky"), due to inertia of the principals (who resist changing their asset allocations) and to contractual obligations with the asset managers (who require long advance notice for capital withdrawal).

Even if hedge fund managers do not read the academic literature while driving their Ferraris (don't read and drive), they still have to make decisions about the risk they want to take the next day, week, and month. There is one line of research, initiated by electrical engineers and mostly developed by researchers not employed by Economics departments, that is relevant to investors. It is broadly known as Kelly Criterion, Kelly Investing, Kelly gambling, Universal Portfolios, Optimal Growth Portfolios, or Optimal Growth Investing. It has both descriptive power, since it is followed by many successful investors, and prescriptive value, in that it is based on first principles and has attractive properties. The rest of this chapter is devoted to presenting the basics of the theory. We start with a description and motivation of the Kelly Criterion. Then we link it to the familiar concepts of Mean-Variance Optimization and Sharpe Ratio. The way that vodka is not suitable as a dinner drink, "Pure" Kelly is not suitable for investing. Fractional Kelly is to Kelly what Chardonnay is to Vodka: more sustainable, better tasting, and ultimately more fun. Finally, we introduce a time-varying version of Fractional Kelly, which helps manage the occurrence of drawdowns.

\section*{13.1. The Kelly Criterion}

One line of research in multi-period investing has been relevant to practitioners: Kelly criterion. To introduce the concept, we consider first a very simple example. You have one risky asset in which to invest, which returns $+100 \%$ or $-50 \%$ with equal probability. The single-period expected return of the asset is $1 / 4$, and its volatility is $3 / 4$. You have to decide how to invest your initial capital in this asset. Consider two alternatives:
1. (Constant Capital Allocation) Every day you allocate the same amount of capital to the risky asset. This approach is consistent with solving a mean-variance optimization problem in each period. The problem faced in every period is
$$
\begin{equation*}
\max _{w} \frac{5}{4} w-\frac{\lambda}{2} \frac{9}{16} w^{2} \Rightarrow w^{*}=\frac{20}{9 \lambda} \tag{13.1}
\end{equation*}
$$
where $w$ is the net amount allocated to the risky asset and is independent of the period.
2. (Static Allocation) On day 0 , you allocate a fraction $x$ of your capital to the risky asset, and then you let it run. This is consistent with solving a mean-variance optimization in period 0 , and letting it run.
3. (Dynamic Allocation) Every day, you allocate a fraction $x$ of your capital on that day to the risky asset. We have no motivation for this (yet). The intuition however is it seems reasonable to have a volatility proportional to the available capital in each period. The ratio of the strategy's volatility to capital in each period is equal to $3 x / 4$ and is indeed constant in this approach.

Figure 13.1 shows the cumulative returns under the three approaches. The constant capital allocation shows low growth. Independently of $x$, the static allocation has poor performance, even though the risky asset has positive expected return. Conversely, the dynamic allocation exhibits a variety of behaviors. Its growth rate (equal to the slope of the curve) is not monotonically increasing with $x$. Risk-adjusted performance is good for low values of $x$, but the average returns are low. The most profitable strategy corresponds to $x=1 / 2$. Higher values detract from performance.

What is remarkable is that, for each strategy, and for each period, the Sharpe Ratio is identical and equal to $1 / 3$, because in each period the portfolio, being the combination of a free-risk asset and a risky asset, is mean-variance efficient. This numerical example should warn about the subtleties of using the Sharpe Ratio as a performance measure. We have been able to compute the Sharpe Ratio exactly, thus abstracting away any complication due to performance measurement; and we obtained the same value for all the strategies in our example. Yet, the behavior of the cumulative returns differs wildly among the
strategies! We can interpret this as follows: the single-period Sharpe Ratio, defined as expected mean return/standard deviation in a single period, is a measure of investor skill, but not of strategy performance. Averaging the Sharpe Ratio over the life of a strategy can give us a better estimate of skill, but is not telling us much about the risk-adjusted performance of the strategy over its lifetime. If we chose the cumulative returns over the strategy lifetime as a metric - and ignored any drawdown concern - then the dynamic strategy with $x^{*}=1 / 2$ would be the clear favorite.

A second observation is that skill alone, defined as the ability to select a high-Sharpe portfolio in any given period, is necessary but not sufficient to be a successful investor. The size of the overall portfolio over time plays a major role in the long term. Yet, this topic does not receive much attention among academics nor practitioners.

To understand where the value $x=1 / 2$ comes from, let $r_{t}(x)$ be the random return of the dynamic allocation strategy in period $t$. It is
$$
1+r_{t}(x)= \begin{cases}1+x & p=1 / 2  \tag{13.2}\\ 1-x / 2 & p=1 / 2\end{cases}
$$

The total return of the strategy is $\prod_{t=1}^{T}\left(1+r_{t}(x)\right)$. The average growth rate of the strategy $g_{T}(x)$ is such that
$$
\begin{aligned}
& \prod_{t=1}^{T}\left(1+r_{t}(x)\right)=\exp \left(T g_{T}(x)\right) \\
& \text { where } g_{T}(x):=\frac{1}{T} \sum_{t=1}^{T} \log \left(1+r_{t}(x)\right)
\end{aligned}
$$

For a fixed number of periods $T$, if we wanted to maximize the expected
growth rate of the strategy, we would solve the problem $\max _{x} g_{T}(x)$. For $T \rightarrow \infty$, because returns are iid rvs, by the law of large numbers, $g_{T}(x) \rightarrow$ $E\left[\log \left(1+r_{1}(x)\right)\right]$ a.s. The solution to the problem
$$
\begin{equation*}
\max _{x} E\left[\log \left(1+r_{1}(x)\right)\right] \tag{13.3}
\end{equation*}
$$
is asymptotically equivalent to maximizing the expectation (13.3). The objective function is maximized when the investment fraction $x$ is equal to $1 / 2$ (see Figure 13.2).

[WILEY EDITORS: place Figure 13.2 around here.]

![](https://cdn.mathpix.com/cropped/2025_02_28_1b91c79c8af4a84b6fbdg-434.jpg?height=646&width=914&top_left_y=1000&top_left_x=562)

Figure 13.2: Expected value of the log of the single-period growth, which is maximized at $x^{\star}=1 / 2$.

From Figure 13.1, it appears that this strategy performs decidedly better than other strategies with lower investment fractions. By simulation (or from Figure 13.2) one can see that any strategy in which $x>1$ performs even worse; this corresponds to borrowing money to invest in the risky asset. Summing up, it appears that long-term returns are maximized not by maximizing the expected
returns, but by maximizing the expected growth rate, which is mathematically equivalent to maximizing an expected utility, with a logarithmic utility function.

[WILEY EDITORS: place Figure 13.1 around here.]

![](https://cdn.mathpix.com/cropped/2025_02_28_1b91c79c8af4a84b6fbdg-432.jpg?height=581&width=1286&top_left_y=455&top_left_x=365)

Figure 13.1: Cumulative returns under the dynamic and static policies. All the same curves are based on the same realization of returns of the risky asset. The returns are plotted on a logarithmic scale.

Let's work out in detail an important example.

Example 13.1(The Kelly allocation to a single security): We have only two assets: a risk-free asset and a risky asset. Let the excess return of the risky asset be $r$ with mean $\mu$ and variance $\sigma^{2}$. One way to interpret this asset in real-world application is as a portfolio manager to which we need to allocate capital. If we were to maximize the expected growth of the portfolio, then we would solve the problem
$$
\begin{equation*}
\max _{x} g(x):=\max _{x} E[\log (1+r x)] \tag{13.4}
\end{equation*}
$$

In addition to an exact numerical solution, we also produce an approximate solution based on the quadratic approximation of the logarithm:
$$
\begin{equation*}
\log (1+x)=x-\frac{x^{2}}{2}+o\left(x^{3}\right) \tag{13.5}
\end{equation*}
$$

Then a quadratic approximation is
$$
\begin{equation*}
\max _{x} E[\log (1+r x)] \simeq \max _{x} \mu x-\frac{1}{2}\left(\sigma^{2}+\mu^{2}\right) x^{2} \tag{13.6}
\end{equation*}
$$
and a further approximation, in which we assume $\mu \ll \sigma$, is
$$
\begin{equation*}
\max _{x} E[\log (1+r x)] \simeq \max _{x} \mu x-\frac{1}{2} \sigma^{2} x^{2} \tag{13.7}
\end{equation*}
$$
from which
$$
\begin{align*}
& \text { (exact result) : }\left\{\begin{array}{l}
x^{\star}=\arg \max _{x} E[\log (1+r x)] \\
g\left(x^{\star}\right)=E\left[\log \left(1+r x^{\star}\right)\right]
\end{array}\right.  \tag{13.8}\\
& \text { (quadratic approximation) : }\left\{\begin{array}{l}
x_{1}^{\star} \simeq \frac{\mu}{\mu^{2}+\sigma^{2}} \\
g\left(x_{1}^{\star}\right) \simeq \frac{1}{2} \frac{\mathrm{SR}^{2}}{\mathrm{SR}^{2}+1}
\end{array}\right.  \tag{13.9}\\
& \text { (assuming that } \mu \ll \sigma):\left\{\begin{array}{l}
x_{2}^{\star} \simeq \frac{\mathrm{SR}}{\sigma} \\
g\left(x_{2}^{\star}\right) \simeq \frac{1}{2} \mathrm{SR}^{2}
\end{array}\right. \tag{13.10}
\end{align*}
$$

This approximate result is reliable when the typical fluctuations of $x r$ are smaller than 1. A heuristic is to require that the volatility of $x^{*} r$ be smaller than $1:\left|x^{*} \sigma\right| \ll 1$, i.e., $|\mathrm{SR}| \ll 1$.

Let us consider in some more detail the accuracy of the approximations $x_{1}^{\star}, x_{2}^{\star}$. We consider daily Gaussian returns. The approximation $x_{1}^{\star}$ is accurate (relative error $\left|x_{1}^{\star}-x^{\star}\right| / x^{\star} \leq 2 \%$ ) for daily Sharpe Ratios up to 0.24 (annualized Sharpe Ratio of 4). The approximation $x_{2}^{\star}$ is accurate (relative error $\left|x_{2}^{\star}-x^{\star}\right| / x^{\star} \leq 2 \%$ ) for daily Sharpe Ratios up to 0.15 (annualized Sharpe Ratios up to 2.4). The crucial assumption in these calculations is the rebalancing interval. If we rebalance at shorter horizons, the volatility of returns in that horizon is smaller, and the quadratic approximation is more accurate. If we rebalanced capital at shorter horizons than daily, the approximation would hold for higher values of the annualized Sharpe Ratio.

Another way to read this result is that the optimal ratio between dollar volatility and capital is equal to the Sharpe Ratio. The capital deployed is $W_{0} x^{\star} \sigma$.

Hence the (dollar volatility)/(capital) ratio is
$$
\begin{equation*}
\frac{(\text { dollar volatility })}{(\text { capital })}=\frac{\left(W_{0} x_{2}^{\star}\right) \sigma}{W_{0}}=\mathrm{SR} \tag{13.11}
\end{equation*}
$$

Note that the formulas above hold for volatilities and Sharpe Ratio measured at the same timescale. For example: if we deploy $\$ 1 \mathrm{~B}$ of capital, and have an annualized Sharpe Ratio of 2, then we should deploy approximately $\$ 2 \mathrm{~B}$ of dollar volatility to run a Kelly-optimal strategy.

Another observation: according to Equation (13.11), the Kelly-optimal expected return is
$$
(\text { expected strategy return })=\mathrm{SR} \times \frac{(\text { dollar volatility })}{(\text { capital })}=\mathrm{SR}^{2}
$$

Example 13.2(The Kelly allocation to the US market): We can specialize the analysis above to the important case in which the risky asset is the US market benchmark. This asset is available to retail investors in the form of low-management fees mutual funds and ETFs, both of which track the US market accurately. Futures for the US markets are also available to sophisticated investors. The Sharpe Ratio computed on the returns of the SP500 in excess of 3-month Treasury bills is a function of starting and ending dates ${ }^{1}$. We assume a Sharpe Ratio of 0.42 and an annualized volatility of $19 \%$. Based on the observed realization of the historical daily returns, the optimal total return is maximized at $x_{1}^{\star}=1.88$ (Equation (13.9) and $x_{2}^{\star}=2.2$ (Equation (13.10). A chart of the cumulative returns ${ }^{2}$ of the SP500 is shown in Figure 13.6. This example suggests that, if our goal was to maximize our long-term returns, then it would be optimal to leverage our capital. In practice, there are borrowing constraints and the live behavior of a Kelly strategy has drawbacks: the historical plot shows how a larger fraction invested results in much more volatile PnL and in larger drawdowns. However, this example illustrates of the invested fraction can have a very dramatic impact on capital appreciation.

[WILEY EDITORS: place Figure 13.6 around here.]

![](https://cdn.mathpix.com/cropped/2025_02_28_1b91c79c8af4a84b6fbdg-437.jpg?height=424&width=1240&top_left_y=1444&top_left_x=394)

Figure 13.3: (a): Time series of cumulative returns for different fractions of the capital invested in the US market benchmark (cap-weighted average of NYSE, AMEX and NASDAQ-listed companies). Monthly excess returns of the benchmark for the period February 1926-March 2018 are from Ken French's data library site. (b): Cumulative returns as a function of the fraction invested in the US market benchmark. The optimal Kelly fraction under the two approximations (Equations (13.9, 13.10)) is $x_{1}^{\star}=1.88$ and $x_{2}^{\star}=2.2$.



The SP500 example shows the attractive features, but also the drawbacks of Kelly strategies.

Example 13.3(Sizing a Bet): Consider a bet with a binary outcome: if we invest $\$ 1$, we receive a payoff equal to $r_{w}>0$ with probability $p$ and $-r_{l}<0$

\footnotetext{
${ }^{1}$ A. Damoradan maintains a page (https://tinyurl.com/spdamor) with SP500 and Treasury returns.
${ }^{2}$ Before January 1957, the SP500 had 90 components. The returns for 1926-1956 use this SP90 index.
}
with probability $q=1-p$. The optimization problem is
$$
\begin{aligned}
& \max _{x} p \log \left(1+x r_{w}\right)+q \log \left(1-x r_{l}\right) \\
& \\
& \frac{p r_{w}}{1+x^{\star} r_{l}}-\frac{q r_{l}}{1-x^{\star} r_{l}}=0 \quad \text { (first-order condition) } \\
& \Rightarrow \\
& x^{\star}=\frac{p}{r_{l}}-\frac{q}{r_{w}}
\end{aligned}
$$

Introduce the win-loss ratio $p / q$, and the winning skew $r_{w} / r_{l}$.
$$
x^{\star}=\frac{p}{r_{l}}\left(1-\frac{1}{(\text { win-loss ratio })} \frac{1}{(\text { winning skew })}\right)
$$

The higher the win-loss ratio and the winning-skew, the higher the size of the bet. If both win-loss ratio and winning skew are smaller than one, the optimal size cannot be positive.

We close this section with a more advanced example.

Example 13.4 (Optimal Strategy for a Geometric Diffusion): Consider a strategy with expected excess return $r$ in a single period and volatility $\sigma$ in the same period, which we can lever by a factor $x(t)>0$. The strategy has return and volatility equal to $x(t) r$ and $x(t) \sigma$. We start with capital $W_{0}$. Over interval $[0, \infty)$, the continuous-time process governing the capital accumulation at time $t$ is
$$
d W_{t}=x(t) \mu W_{t} d t+x(t) \sigma W_{t} d B_{t}
$$

Here, $B_{t}$ is a standard Brownian process. It can be shown that the distribution
at time $t$ is given by
$$
W_{T}=W_{0} \exp \left[\int_{0}^{T}\left(x(t) \mu-\frac{1}{2} x^{2}(t) \sigma^{2}\right) d t+\int_{0}^{T} x(t) \sigma d B_{t}\right]
$$

Hence
$$
g_{T}(x)=\frac{1}{T} \int_{0}^{T}\left(x(t) \mu-\frac{1}{2} x^{2}(t) \sigma^{2}\right) d t+\frac{1}{T} \int_{0}^{T} x(t) \sigma d B_{t}
$$

For $T \rightarrow \infty$ the second integral converges to zero a.s. (for intuition: $B_{t}$ scales like $\sqrt{t}$ ). The first integral is maximized when the integrand is maximized for all $t$, which occurs when $x(t)=\mu / \sigma^{2}=\mathrm{SR} / \sigma$. We have recovered Equation (13.10).

In our presentation, we have ignored two important features:
- The Sharpe Ratio is a decreasing function of the capital $x$ allocated to the active strategy. Modeling this dependency explicitly is challenging, and to my knowledge there is no analysis where $\mu$ is a function of $x$. The formula $x^{\star}=\mathrm{SR} / \sigma$ does not hold any longer. At the very least, we should acknowledge this dependency in the ideal formula, and solve for the allocation that solves the equation $x=\operatorname{SR}(x) / \sigma$.
- There are transaction costs even in the case of a static $x^{\star}$. Whenever the active strategy has a positive PnL , in order to maintain a fraction $x^{\star}$ in the active strategy, we need to partially trade out of the policy and allocate to the risk-free asset. The dollar amount we need to trade in order to maintain the fraction $x^{\star}$ is
$$
\frac{W_{t} x^{\star}\left(1+r_{t}\right)+\delta_{t}}{W_{t}\left[x^{\star}\left(1+r_{t}\right)+\left(1-x^{\star}\right)\right]}=x^{\star} \Rightarrow \delta_{t}=\frac{1-x^{\star}}{1+r_{t}} W_{t} r_{t}
$$

Trading costs are super-linear in $\delta_{t}$, and therefore super-linear in $W_{t}$, and become dominant as wealth grows. HIC SVNT LEONES.

The next section is devoted to describing the attractive mathematical properties of Kelly strategies.

\section*{13.2. Mathematical Properties}

We limit our attention to the case in which we can choose in each period among a set of strategies $\Theta$, and the associated returns $r_{t}(\theta)$ are independent of $r_{t^{\prime}}(\theta)$, for all $t^{\prime}<t$. These results were proved first by Breiman [1961] and Dubins and Savage [1965], but some of them have also been established for dependent random variables; see Algoet and Cover [1988].

Let $X_{t}, Y_{t}$ be the cumulative returns of the Kelly strategy, and of an alternative strategy with lower expected growth rate.
1. The first property is that the Kelly strategy grows faster, than any strategy with lower expected growth rate. Let $X_{t}, Y_{t}$ the cumulative returns of the Kelly strategy and alternative strategy respectively. Then, with probability 1 ,
$$
\begin{equation*}
\lim _{t \rightarrow \infty} \frac{X_{t}}{Y_{t}}=\infty \tag{13.12}
\end{equation*}
$$
2. The second property characterizes the long-term growth of a strategy based on the expected value of its $\log$ returns. Let $g:=E\left[\log \left(1+r_{1}\right)\right]$ and $X_{t}$ the associated cumulative return process. Then, with probability 1
(a) $g>0 \Rightarrow X_{t} \rightarrow \infty$
(b) $g<0 \Rightarrow X_{t} \rightarrow-\infty$
(c) $g=0 \Rightarrow \limsup _{t} X_{t}=\infty, \liminf _{t} X_{t}=-\infty$.
3. The expected time to reach capital level $C$ is equal to $\log C / g$ in the limit $C \rightarrow \infty$, and it is shortest for the Kelly strategy.

\subsection*{Insight 13.1: The intuition behind Kelly strategies}

The Kelly criterion for sizing has several intuitive and attractive features:
- Goal: The allocation strategy achieves the highest long-term capital growth.
- Simplicity: The optimal strategy is simple, since it allocates a constant fraction of total capital to the risky strategy.
- Lower and Upper Bound on risky allocation: the fraction of capital allocated to a risky strategy should be high enough to ensure growth $g>0$, and at most equal to $x^{\star}$.
- Sharpe-proportional: to a first approximation, the optimal fraction of invested capital and the volatility/capital ratio are proportional to the Sharpe Ratio of the strategy.

What these result say is that a Kelly strategy has many very desirable features. In the long run, it beats almost surely any other strategy that has a different expected growth rate. It also reaches a certain cumulative return faster than any other strategy; and the approximate time needed to reach this return can be expressed as a function of $g$. Finally, a positive expected growth rate is a necessary and sufficient condition for any strategy to have a growing cumulative return over time ${ }^{3}$.

\footnotetext{
${ }^{3}$ There are other properties of the Kelly Strategy. See MacLean et al. [2010a] for a review, and Part IV of the book MacLean et al. [2010b] for a diversity of views.
}

What the results don't say is that a Kelly Strategy is maximizing the Sharpe Ratio, even if we were able to compute it exactly from knowledge of the true expected return and volatility of the strategy. Nor does it guarantee any lower bound on the maximum drawdowns, which can be severe, as seen in the simulations above. In example 13.2, the fraction $x$ invested increases from 0 to the growth-maximizing level $x^{*}$, both the growth rate and the size of the drawdowns increase with $x$. The scale of the y axis is logarithmic. The excursion of the returns is therefore proportional to the drawdown percentage. Above the optimal level, the growth rate diminishes (as expected) and the drawdowns increase further. For fractions of the invested wealth lower than $x^{*}$, there is a trade-off between expected log returns and volatility of the log returns: we get lower returns, in exchange for lower risk. We explore this trade-off next.

\section*{13.3. The Fractional Kelly Strategy}

The fractional Kelly strategy consists of investing in a strategy with iid return $r_{t}$ a fraction $x_{\text {frac }}^{\star}$ of the available capital smaller than $x^{\star}$, but still such that $E\left[\log \left(1+r_{1} x_{\text {frac }}^{\star}\right)\right]>1$. If can be interpreted in several ways:
- Combination of risk-free asset and full Kelly. Fractional Kelly is combination of two investments: a risk-free asset, and the full Kelly strategy. The percentage volatility of the strategy is $\sigma x_{\text {frac }}^{\star}$. This is the line of analysis pursued by MacLean et al. [1992]. They show [MacLean et al., 2004, 2010a] that the fractional Kelly strategy does indeed trade off growth for security. Assume, for example, that in each period we cannot tolerate a percentage volatility greater than some value $p$. This threshold is related to the maximum drawdown per period that we can accept. From Equation (13.11), $x \sigma \leq p$. We choose the minimum of the $x^{\star}=\min \{p / \sigma, \mathrm{SR}\}$.

Example 13.5: We deploy $\$ 1 B$ of capital, and have a Sharpe Ratio of 2. The strategy has a percentage volatility of $5 \%$. We can lose at most $1 \%$ of our capital in a week. Say that $3 \times($ weekly dollar volatility $)=0.01 \times($ capital $)$, i.e.,
$$
p=\frac{(\text { weekly dollar volatility })}{(\text { capital })}=0.01 / 3
$$

So that $p / \sigma=0.11$. This is smaller than the weekly Sharpe Ratio $2 / \sqrt{52} \approx$ 0.27, which corresponds to the optimal Kelly fraction.
- Higher risk aversion. We start from Equation (13.6), which approximates the $\log$ objective function with a linear-quadratic one. We modify the approximate objective function by overweighting the quadratic penalty:
$$
\max _{x} \mu x-\frac{\lambda}{2}\left(\sigma^{2}+\mu^{2}\right) x^{2}, \quad \theta>1
$$

The optimization point is
$$
x_{\text {frac }}^{\star}=\frac{x^{\star}}{\lambda}
$$

Fractional Kelly is then a modified Kelly strategy for investors who are more risk-averse than logarithmic utility would suggest ${ }^{4}$.
- Parameter uncertainty. Thorp [2006] makes the case that uncertainty about the properties of returns should result in fractional Kelly. Indeed, being wrong can have terrible consequences. Imagine, for example, that we have a strategy with a volatility of $19 \%$, and an estimate of Sharpe Ratio equal to 0.84 the realized Sharpe Ratio is 0.42 . The Kelly fraction is 4.4 . We over-leverage the strategy and go bankrupt (see Figure 13.6, bottom panel, for a historical simulation based on the returns of the Market).

\footnotetext{
${ }^{4}$ The relationship between this mean-variance approximation and power utility function $u(x) \propto u^{\gamma}$, for $\gamma>0$, is explored by Pulley [1981].
}

We have introduced parameter uncertainty already in Section 10.2.2, in the context of mean-variance optimization. An argument for this approach is the following. We model parameter uncertainty as follows. Per-period returns are $r_{t}=r\left(\omega_{t}, \theta_{t}\right)$, where $r_{t}$ is a function of two iid random variables $\omega_{t}$ (the sample in the probability space $\Omega_{t}$, with probability measure $P_{\omega}$ ) and $\theta_{t}$ (a random parameter taking values in a set $\Theta$, with probability measure $P_{\theta}$ ). The interpretation is that in every period we have a noisy estimate of the true parameter $\bar{\theta}:=E_{\theta}\left(\theta_{t}\right)$. We make the assumptions that $r\left(\omega_{t}, \theta_{t}\right)$ is twice differentiable in $\theta_{t}$ and that $\partial^{2} r / \partial \theta_{t}^{2} \leq 0$. The log total return is
$$
\begin{aligned}
g_{T}(x) & :=\frac{1}{T} \sum_{t=1}^{T} \log \left(1+x r\left(\omega_{t}, \theta_{t}\right)\right) \\
g(x) & :=\lim _{T \rightarrow \infty} g_{T}(x) \\
& =E_{\omega, \theta}[\log (1+x r(\omega, \theta))] \quad \text { a.s. }
\end{aligned}
$$

The expectation is taken with respect to the random variables $\omega \sim P_{\omega}$ and $\theta \sim P_{\theta}$. We want to maximize $g(x)$. The first-order condition is $g^{\prime}(x)=0$ :
$$
\begin{aligned}
g^{\prime}(x) & =E_{\omega} E_{\theta}\left[\frac{r(\omega, \theta)}{1+x r(\omega, \theta)}\right] \\
g\left(x_{\text {uncert }}^{\star}\right) & =0
\end{aligned}
$$

As a function of $r$, the function $h(r):=r /(1+x r)$ is increasing and strictly concave. Then it follows that, as a function of $\theta, h(r(\theta))$ is concave, because
$$
\frac{\partial^{2} h(r(\theta))}{\partial \theta^{2}}=h^{\prime \prime}(r) r^{2}+h^{\prime}(r) \frac{\partial^{2} r}{\partial \theta^{2}} \leq 0
$$

By Jensen's inequality,
$$
E_{\theta}\left[\frac{r(\omega, \theta)}{1+x r(\omega, \theta)}\right]<\frac{r(\omega, \bar{\theta})}{1+x r(\omega, \bar{\theta})}
$$

And therefore, taking expectations over $\omega$,
$$
g^{\prime}(x)=E_{\omega} E_{\theta}\left[\frac{r(\omega, \theta)}{1+x r(\omega, \theta)}\right]<E_{\omega}\left[\frac{r(\omega, \bar{\theta})}{1+x r(\omega, \bar{\theta})}\right]=: g_{0}(x)
$$

[WILEY EDITORS: place Figure 13.4 around here.]

![](https://cdn.mathpix.com/cropped/2025_02_28_1b91c79c8af4a84b6fbdg-446.jpg?height=500&width=1037&top_left_y=514&top_left_x=479)

Figure 13.4: The optimal Kelly size in the presence of parameter uncertainty is always smaller than the optimal size when parameters are known.


The function on the left-hand side is the derivative of the expected log return in the presence of parameter uncertainty. The function on the right-hand side is the derivative of the expected log return when the parameter is known. It follows that $x_{\text {uncert }}^{\star} \leq x^{\star}$. Figure 13.4 visually illustrates the location of the two solutions.

Let us consider two examples that have some general application: uncertainty about a strategy's expected return and about its variance.

Example 13.6(Strategy with uncertain expected return): Let $r=\theta+$ $\sigma \xi$, where $\xi$ is a rv with zero mean and unit variance, and $\theta$ is random, with $E(\theta)=\mu$ and $\operatorname{var}(\theta)=\tau^{2}$. We assume that $\xi$ and $\theta$ are independent. In this case $\partial^{2} r / \partial \theta^{2}=0$.
$$
E[\log (1+r x)] \simeq \mu x-\frac{1}{2}\left(\mu^{2}+\sigma^{2}+\tau^{2}\right) x^{2}
$$
so that the Kelly fraction is
$$
x_{1}^{\star} \simeq \frac{\mu}{\mu^{2}+\sigma^{2}+\tau^{2}}
$$

Let us use the SP500 rough market estimates from previous examples: $\sigma=0.19, \mu=0.08$, and $a \tau=0.04$. We get $x_{1}^{\star}=1.81$, compared to an estimate of 1.88 in the absence of estimation error.

Example 13.7(Strategy with uncertain volatility): Let $r=\mu+(\sigma+\tau \theta) \xi$, where $\tau>0$ and $\xi, \theta$ are rvs with mean zero and unit variance. We assume that $\xi$ and $\theta$ are independent. Also in this case $\partial^{2} r / \partial \theta^{2}=0$.
$$
\begin{aligned}
E[\log (1+r x)] & \simeq \mu x-\frac{1}{2}\left[\mu^{2}+E\left((\sigma+\tau \theta)^{2} \xi^{2}\right)\right] x^{2} \\
& =\mu x-\frac{1}{2}\left(\mu^{2}+\sigma^{2}+\tau^{2}\right) x^{2}
\end{aligned}
$$
so that the Kelly fraction is again
$$
x_{1}^{\star} \simeq \frac{\mu}{\mu^{2}+\sigma^{2}+\tau^{2}}
$$

Let us use the SP500 rough market estimates from previous examples: $\sigma=0.19, \mu=0.08$, and $\tau=0.1$ for the market return. We get $x_{1}^{\star}=1.81$,
compared to an estimate of 1.52 in the absence of estimation error.

\subsection*{Insight 13.2: All reasonable investors use Fractional Kelly without knowing}
All reasonable investors allocate capital to a risky strategy so that the volatility/capital ratio is constant, or slowly varying. This is in line with the first justification we gave to fractional Kelly strategies. In other words, they want to allocated as much capital as it's possible, compatibly with the drawdowns that their investors can bear. In a series of papers (Part VI of MacLean et al. [2010b] collects the contributions on this subject) Ziemba and coauthors provide anecdotal evidence that successful investors follow Kelly allocations. The likely reason is not that investors are aware of the Kelly criterion, but rather that they use the simple constant vol/capital heuristic, which turns out to be equal to Fractional Kelly.

\section*{13.4. Fractional Kelly and Drawdown Control}

In an influential paper, Grossman and Zhou [1993] address a question related to that of identifying a growth-optimal strategy and of controlled growth-optimal optimization. In the Grossman-Zhou formulation (GZ henceforth), the investor wants to maximize the long-term growth and with probability one avoid reaching a drawdown threshold. As formulated in their original paper, the model only considers a risk-free asset and a risky one following a geometric diffusion with mean $\mu$ and volatility $\sigma$. We introduced this model in Example 13.4. In order to formulate the policy we define the high watermark of the wealth process $W_{t}$
as $M_{t}=\max \left\{W_{s}: t \in[0, t]\right\}$. Let $d_{t}$ be the current drawdown percentage from the high watermark: $d_{t}:=1-W_{t} / M_{t}$. Let the maximum allowed percentage drawdown be $D$. The optimal policy gives the optimal fraction invested in the risky asset and is given by
$$
\begin{equation*}
f_{t}=\frac{\mu}{\sigma^{2}}\left(1-\frac{1-D}{1-d_{t}}\right) \tag{13.13}
\end{equation*}
$$

This policy is elegant and intuitive. For some intuition, fix first, $D=1$; i.e., we can tolerate infinite drawdown. Then the strategy is the one we identified in Eq.13.6: invest a fixed fraction $x^{*}=\mu / \sigma^{2}$. If $0<D<1$, then the optimal strategy is to invest a fraction $x^{*} D$ when we are at the high watermark $d_{t}=0$. This means that we are more prudent than in the simple Kelly scenario, and we are more prudent if our threshold is conservative; a "dynamic fractional Kelly" with maximum fraction $D$ of the optimal Kelly. The less tolerant we are of drawdowns, the smaller the fraction. Moreover, we decrease the invested fraction as we approach the drawdown threshold, and we liquidate the risky asset Figure 13.5 shows the optimal fraction as a function of the threshold. The reduction rate is nearly constant over the range of allowed drawdowns.

[WILEY EDITORS: place Figure 13.5 around here.]

![](https://cdn.mathpix.com/cropped/2025_02_28_1b91c79c8af4a84b6fbdg-450.jpg?height=676&width=936&top_left_y=665&top_left_x=519)

Figure 13.5: Percentage reduction factor $1-(1-D) /\left(1-d_{t}\right)$.

The strategy is a continuous version of stop-loss policies employed by many hedge funds and successful investors. In the presence of a large drawdown, a portfolio manager operating autonomously within the fund, is required to partially or completely liquidate her portfolio. The strategy has many interpretations. One interpretation of a stop-loss policy is a tail insurance policy on the strategy itself. View the policy as a synthetic asset, whose price is $W_{t}$. Imagine that we hold an out-of-the-money put on strategy.

To understand the trade-offs between optimizing for variance control and optimizing for drawdown control, it is useful to compare the GZ and Fractional Kelly strategies in a numerical examples. Specifically, we consider the case of a risky asset with independent identically distributed returns. Its expected daily return is $0.08 \%$ and its daily volatility is $1 \%$, corresponding to a Sharpe Ratio of 1.27. The two strategies are parametrized by the Kelly fraction and the drawdown threshold respectively, i.e.
$$
\begin{align*}
f_{t}(p) & =p \frac{\mu}{\sigma^{2}} & & \text { (Fractional Kelly) }  \tag{13.14}\\
f_{t}(D) & =\frac{\mu}{\sigma^{2}}\left(1-\frac{1-D}{1-d_{t}}\right) & & \text { (Grossman-Zhou) } \tag{13.15}
\end{align*}
$$
with $p \in(0,1), D \in(0,1)$. I then simulate the performance of the two strategies over a 100-year period (i.e., 25,200 days) and compare the realized volatility and the maximum drawdown for strategies having the same expected log-return. Fig. 13.6 shows the results. As expected, the fractional Kelly strategy has a
better profile than GZ in the mean-volatility plane, and a worse one in the mean-maximum drawdown one. In this numerical example, the reduction in drawdown of GZ seems more marked than the associated increase in volatility.

[WILEY EDITORS: place Figure 13.6 around here.]

![](https://cdn.mathpix.com/cropped/2025_02_28_1b91c79c8af4a84b6fbdg-451.jpg?height=630&width=1351&top_left_y=433&top_left_x=376)

Figure 13.6: Comparison of fractional Kelly and Grossman-Zhou strategies. Both strategies' performance measures are estimated over the same sequence of 25,200 returns, but with different parameters $p, D$. (a) Standard Deviation of daily log-returns vs mean log-return. (b) Maximum drawdown.

For example, consider a max tolerated drawdown of $30 \%$. GZ achieves an average daily return of approximately $0.09 \%$, while fractional Kelly achieves an average daily return of $0.075 \%$, a $20 \%$ increase. More importantly, GrossmanZhu controls the maximum drawdown ex ante, with probability one and independently of misspecification of the problem. In the fractional Kelly approach, we can at best provide a probabilistic bound on the drawdown; moreover, if the parameters in the optimization problem are incorrect, this bound will be incorrect as well. These considerations suggest that the GZ strategy may be preferable. There is an important qualification to this statement. Throughout this chapter, we have ignored the role played by transaction costs. As we mentioned above, a static fractional Kelly policy requires the continuous allocation of capital to/from a risk-free asset and the active strategy. In GZ, the fraction allocated to the strategy itself is varying over time, sometimes very rapidly in the event of a sudden drawdown, since we may force a complete liquidation of the risky asset when we reach the threshold. This in turn may affect the profitability of the strategy and make the approach less attractive. It is beyond the scope of this chapter to extend the analysis to the case of transaction costs which, in the absence of analytical results, may only be tractable with numerical experiments. These objections notwithstanding, GZ is a useful heuristic that can be used as an overlay to a Kelly-like strategy.


\subsection*{Insight 13.3: Modulating volatility reduces the Sharpe Ratio}

The GZ criterion changes capital allocation, and hence volatility, over time. Changing the volatility of a strategy when the volatility is independent of the expected return of the strategy is Sharpe-reducing. To gain intuition about this fact, consider the simple example of a strategy with Sharpe Ratio equal to $s$. Half of the year we deploy a volatility $\sigma / 2$, and half of the year a volatility $(3 / 2) \sigma$. The expected PnL for the entire year is $((1 / 2) s \sigma+(3 / 2) s \sigma) / 2=s \sigma$. The annualized volatility is $\sqrt{(\sigma / 2)^{2} / 2+(s \sigma(3 / 2))^{2} / 2}=\sqrt{10 / 8} \sigma$. The Sharpe Ratio is $\sqrt{8 / 10} s$. Compare to the case in which we had kept the volatility constant at the value $\sqrt{10 / 8} \sigma$. The Sharpe Ratio would have been $s$. This example can be generalized, and shows that drawdown control doesn't come for free.

\section*{The Takeaways}
1. The policy that generates the highest capital growth in the long-run is the Kelly criterion
2. The Kelly criterion prescribes that we allocate a constant fraction of our capital over time to our active strategy that is equal to the Sharpe Ratio of the strategy, divided by its percentage volatility.
3. The Kelly Criterion has the undesirable property of incurring into large drawdowns over time.
4. To alleviate this problem, we can adopt the fractional Kelly criterion, which allocate a constant, smaller fraction of capital to our active strategy. It trades off growth for higher security.
5. It is further possible to modify the Kelly criterion, so that the fraction of capital is a function of the maximum tolerable drawdown, and that this fraction is linearly decreasing as a function of the drawdown size. The strategy trades off further growth in exchange for a deterministic guarantee on the experienced drawdown.
6. Many successful investors naturally follow a fractional Kelly with drawdown control.
7. All of these simple strategies are valid in the absence of transaction costs, and need to be simulated and calibrated in real-world applications, in order to account for such costs.
