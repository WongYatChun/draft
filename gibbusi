import torch
import torch.nn as nn
import torch.optim as optim

class CustomMLPRegressor:
    def __init__(self, hidden_layer_sizes=(100,), activation='relu', solver='adam', learning_rate=0.001, max_iter=200, fit_intercept=True):
        self.hidden_layer_sizes = hidden_layer_sizes
        self.activation = activation
        self.solver = solver
        self.learning_rate = learning_rate
        self.max_iter = max_iter
        self.fit_intercept = fit_intercept
        self.model = None

    def _build_model(self, input_size):
        layers = []
        previous_size = input_size
        
        for size in self.hidden_layer_sizes:
            layers.append(nn.Linear(previous_size, size))
            if self.activation == 'relu':
                layers.append(nn.ReLU())
            elif self.activation == 'tanh':
                layers.append(nn.Tanh())
            previous_size = size
        
        layers.append(nn.Linear(previous_size, 1))
        
        if not self.fit_intercept:
            for layer in layers:
                if isinstance(layer, nn.Linear):
                    layer.bias.requires_grad = False
        
        self.model = nn.Sequential(*layers)
    
    def fit(self, X, y):
        X = torch.tensor(X, dtype=torch.float32)
        y = torch.tensor(y, dtype=torch.float32).view(-1, 1)
        
        input_size = X.shape[1]
        self._build_model(input_size)
        
        if self.solver == 'adam':
            optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)
        elif self.solver == 'sgd':
            optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate)
        
        criterion = nn.MSELoss()
        
        for epoch in range(self.max_iter):
            self.model.train()
            optimizer.zero_grad()
            outputs = self.model(X)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()

    def predict(self, X):
        X = torch.tensor(X, dtype=torch.float32)
        self.model.eval()
        with torch.no_grad():
            predictions = self.model(X).numpy()
        return predictions

# Example usage
if __name__ == "__main__":
    # Generating some sample data
    import numpy as np
    X = np.random.rand(100, 3)
    y = np.random.rand(100)

    # Training the custom MLP regressor
    mlp = CustomMLPRegressor(hidden_layer_sizes=(50, 30), max_iter=500, fit_intercept=False)
    mlp.fit(X, y)

    # Making predictions
    predictions = mlp.predict(X)
    print(predictions)
