import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

class WeightPredictorModel(nn.Module):
    def __init__(self, input_dim, hidden_units=10, dropout_rate=0.5):
        super(WeightPredictorModel, self).__init__()
        self.hidden = nn.Linear(input_dim, hidden_units)
        self.dropout = nn.Dropout(dropout_rate)
        self.output = nn.Linear(hidden_units, input_dim)
    
    def forward(self, x):
        x = torch.relu(self.hidden(x))
        x = self.dropout(x)
        x = self.output(x)
        return x

class WeightPredictor:
    def __init__(self, input_dim, hidden_units=10, lr=0.01, batch_size=32, epochs=1000, patience=10, reg_lambda=0.01, dropout_rate=0.5):
        self.model = WeightPredictorModel(input_dim, hidden_units, dropout_rate)
        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)
        self.batch_size = batch_size
        self.epochs = epochs
        self.patience = patience
        self.reg_lambda = reg_lambda  # Regularization factor
        self.criterion = self.custom_loss  # Correctly assigning the custom loss function

    def custom_loss(self, y_true, y_pred, X):
        predictions = torch.sum(X * y_pred, axis=1)
        mse_loss = torch.mean((predictions - y_true) ** 2)
        
        # L2 regularization
        l2_reg = sum(param.pow(2.0).sum() for param in self.model.parameters())
        loss = mse_loss + self.reg_lambda * l2_reg
        
        return loss

    def fit(self, X, Y):
        dataset = TensorDataset(X, Y)
        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)
        best_loss = float('inf')
        wait = 0

        for epoch in range(self.epochs):
            epoch_loss = 0.0
            self.model.train()  # Set model to training mode
            for X_batch, Y_batch in dataloader:
                self.optimizer.zero_grad()
                weights_batch = self.model(X_batch)
                loss = self.criterion(Y_batch, weights_batch, X_batch)  # Using self.criterion
                loss.backward()
                self.optimizer.step()
                epoch_loss += loss.item()

            epoch_loss /= len(dataloader)

            if epoch % 100 == 0:
                print(f"Epoch {epoch}, Loss: {epoch_loss}")

            # Early stopping check
            if epoch_loss < best_loss:
                best_loss = epoch_loss
                wait = 0
            else:
                wait += 1
                if wait >= self.patience:
                    print(f"Early stopping at epoch {epoch}")
                    break

    def predict(self, X):
        self.model.eval()  # Set model to evaluation mode
        with torch.no_grad():
            predicted_weights = self.model(X).numpy()
        return predicted_weights

    def evaluate(self, X, Y):
        predicted_weights = self.predict(X)
        predictions = torch.sum(X * torch.tensor(predicted_weights), axis=1).numpy()
        print("Predicted Y:", predictions[:5])
        print("Actual Y:", Y.numpy()[:5])
        return predicted_weights, predictions

# Example usage
np.random.seed(0)
torch.manual_seed(0)
X = np.random.rand(100, 3).astype(np.float32)
true_weights = np.array([1.5, -2.0, 1.0], dtype=np.float32)
Y = (X @ true_weights + np.random.normal(0, 0.1, 100)).astype(np.float32)

# Convert to PyTorch tensors
X_tensor = torch.tensor(X)
Y_tensor = torch.tensor(Y)

# Initialize and train the model
model = WeightPredictor(input_dim=X.shape[1])
model.fit(X_tensor, Y_tensor)

# Evaluate the model
predicted_weights, predictions = model.evaluate(X_tensor, Y_tensor)

print("Predicted weights for the first 5 samples:")
print(predicted_weights[:5])
