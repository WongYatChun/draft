{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n## 0) Returns, Covariance, PCA, and Standardization\n\n* **Objects and shapes**\n\n  * **Returns:** $R_t\\in\\mathbb{R}^N$ (excess returns).\n  * **Mean:** $\\mu=\\mathbb{E}[R_t]\\in\\mathbb{R}^N$.\n  * **Covariance:** $\\Sigma=\\operatorname{Var}(R_t)=\\mathbb{E}[(R_t-\\mu)(R_t-\\mu)^\\top]\\in\\mathbb{R}^{N\\times N}$, symmetric p.s.d.\n\n* **PCA / spectral decomposition**\n\n  * Write\n\n    $$\n    \\Sigma = F\\Psi^2 F^\\top,\n    $$\n\n    where:\n\n    * $F\\in\\mathbb{R}^{N\\times N}$ is **orthogonal**: $F^\\top F=FF^\\top=I$. Columns are eigenvectors of $\\Sigma$.\n    * $\\Psi=\\operatorname{diag}(\\psi_1,\\dots,\\psi_N)\\succ 0$ with $\\psi_n=\\sqrt{\\lambda_n}$ (square roots of eigenvalues).\n\n* **Rotate into PC space**\n\n  * Define **PC coordinates**:\n\n    $$\n    Y_t \\;\\equiv\\; F^\\top(R_t-\\mu)\\in\\mathbb{R}^N.\n    $$\n  * Compute the covariance step-by-step:\n\n    $$\n    \\begin{aligned}\n    \\operatorname{Cov}(Y_t)\n    &= \\mathbb{E}\\!\\big[Y_t Y_t^\\top\\big]\n     = \\mathbb{E}\\!\\big[F^\\top(R_t-\\mu)(R_t-\\mu)^\\top F\\big] \\\\\n    &= F^\\top\\,\\mathbb{E}\\!\\big[(R_t-\\mu)(R_t-\\mu)^\\top\\big]\\,F\n     = F^\\top \\Sigma F \\\\\n    &= F^\\top (F\\Psi^2 F^\\top) F\n     = (F^\\top F)\\Psi^2(F^\\top F)\n     = \\Psi^2.\n    \\end{aligned}\n    $$\n\n    So PCs are **uncorrelated** with variances $\\psi_n^2$.\n\n* **Standardize PCs to unit variance**\n\n  * Define **standardized shocks**:\n\n    $$\n    v_t \\;\\equiv\\; \\Psi^{-1}Y_t\n    \\;=\\; \\Psi^{-1}F^\\top(R_t-\\mu)\\in\\mathbb{R}^N.\n    $$\n  * Verify mean and covariance:\n\n    $$\n    \\mathbb{E}[v_t] = \\Psi^{-1}\\underbrace{\\mathbb{E}[Y_t]}_{0}=\\mathbf{0},\\qquad\n    \\operatorname{Cov}(v_t) = \\Psi^{-1}\\operatorname{Cov}(Y_t)\\Psi^{-1}\n    = \\Psi^{-1}\\Psi^2\\Psi^{-1} = I.\n    $$\n\n    Each component of $v_t$ has **variance 1** and components are **uncorrelated**.\n\n* **Reconstruct returns from standardized shocks**\n\n  * From $Y_t=\\Psi v_t$ and $Y_t=F^\\top(R_t-\\mu)$:\n\n    $$\n    F^\\top(R_t-\\mu) = \\Psi v_t \\;\\Rightarrow\\; R_t-\\mu = F\\Psi v_t.\n    $$\n  * **Working representation:**\n\n    $$\n    \\boxed{R_t = \\mu + F\\Psi v_t, \\quad \\mathbb{E}[v_t]=0,\\; \\operatorname{Cov}(v_t)=I.}\n    $$\n\n---\n\n## 1) Covariance and Its Inverse (with proof)\n\n* From PCA:\n\n  $$\n  \\Sigma = F\\Psi^2 F^\\top.\n  $$\n* **Inverse identity** for orthogonal $F$ and diagonal positive $\\Psi^2$:\n\n  $$\n  \\Sigma^{-1} = F\\Psi^{-2}F^\\top.\n  $$\n\n  **Verification:**\n\n  $$\n  \\begin{aligned}\n  \\Sigma \\,\\big(F\\Psi^{-2}F^\\top\\big)\n  &= \\big(F\\Psi^2F^\\top\\big)\\big(F\\Psi^{-2}F^\\top\\big)\n   = F\\underbrace{\\Psi^2\\Psi^{-2}}_{I}F^\\top\n   = FF^\\top\n   = I,\\\\\n  \\big(F\\Psi^{-2}F^\\top\\big)\\Sigma\n  &= F\\Psi^{-2}\\underbrace{F^\\top F}_{I}\\Psi^2F^\\top\n   = F\\underbrace{\\Psi^{-2}\\Psi^2}_{I}F^\\top\n   = I.\n  \\end{aligned}\n  $$\n\n---\n\n## 2) Information Sources and Conditional Expected Returns\n\n* **Signals**\n\n  $$\n  s_t\\in\\mathbb{R}^M,\\qquad \\mathbb{E}[s_t]=0,\\qquad \\operatorname{Cov}(s_t)=I_M.\n  $$\n\n* **Skill matrix (PC–signal cross-covariance)**\n\n  $$\n  K \\;\\equiv\\; \\mathbb{E}[\\,v_t s_t^\\top\\,]\\in\\mathbb{R}^{N\\times M}.\n  $$\n\n* **Joint second moments of $(v_t,s_t)$ (for clarity)**\n\n  $$\n  \\operatorname{Cov}\\!\\begin{pmatrix} v_t \\\\ s_t \\end{pmatrix}\n  = \\begin{pmatrix}\n      \\operatorname{Cov}(v_t) & \\operatorname{Cov}(v_t,s_t) \\\\\n      \\operatorname{Cov}(s_t,v_t) & \\operatorname{Cov}(s_t)\n    \\end{pmatrix}\n  = \\begin{pmatrix}\n      I_N & K \\\\\n      K^\\top & I_M\n    \\end{pmatrix}.\n  $$\n\n* **Conditional mean of $v_t$ given $s_t$** (best linear predictor; exact under joint normality):\n\n  $$\n  \\boxed{\\;\\mathbb{E}[v_t\\mid s_t]\n  = \\operatorname{Cov}(v_t,s_t)\\,\\operatorname{Cov}(s_t)^{-1}\\,s_t\n  = K\\,I_M^{-1}\\,s_t\n  = K s_t.\\;}\n  $$\n\n  *(Shapes: $K\\in\\mathbb{R}^{N\\times M}$, $s_t\\in\\mathbb{R}^M$ ⇒ $Ks_t\\in\\mathbb{R}^N$.)*\n\n* **Signal-driven conditional expected return (alpha)**\n\n  $$\n  \\begin{aligned}\n  a(s_t)\n  &\\;\\equiv\\; \\mathbb{E}[R_t\\mid s_t]-\\mu\n   \\;=\\; \\mathbb{E}[F\\Psi v_t\\mid s_t]\n   \\;=\\; F\\Psi\\,\\mathbb{E}[v_t\\mid s_t] \\\\\n  &= F\\Psi K s_t.\n  \\end{aligned}\n  $$\n\n  $$\n  \\boxed{\\;a(s_t)=F\\Psi K s_t.\\;}\n  $$\n\n---\n\n## 3) Mean–Variance Portfolio for Given Signals\n\n* **Problem**\n\n  $$\n  \\max_{p\\in\\mathbb{R}^N}\n  \\;\\; a(s_t)^\\top p - \\frac{\\lambda}{2}\\,p^\\top \\Sigma\\,p,\n  \\qquad \\lambda>0.\n  $$\n* **FOC and solution (strict concavity from $\\Sigma\\succ0$)**\n\n  $$\n  \\nabla_p:\\; a(s_t)-\\lambda\\Sigma p=\\mathbf{0}\n  \\;\\Longrightarrow\\;\n  \\boxed{\\;p(s_t)=\\frac{1}{\\lambda}\\Sigma^{-1}a(s_t).\\;}\n  $$\n* **(Optional) Value at optimum**\n  Substitute $p(s_t)$ back:\n\n  $$\n  a^\\top p - \\tfrac{\\lambda}{2}p^\\top\\Sigma p\n  = \\tfrac{1}{\\lambda}a^\\top\\Sigma^{-1}a - \\tfrac{\\lambda}{2}\\cdot \\tfrac{1}{\\lambda^2}a^\\top\\Sigma^{-1}\\Sigma\\Sigma^{-1}a\n  = \\frac{1}{2\\lambda}\\,a^\\top\\Sigma^{-1}a.\n  $$\n\n---\n\n## 4) Generalized Information Ratio (GIR)\n\n* **Definition (ex-ante Sharpe of $p(s_t)$)**\n\n  $$\n  GIR \\;\\equiv\\;\n  \\frac{\\mathbb{E}[\\,a(s_t)^\\top p(s_t)\\,]}\n       {\\sqrt{\\mathbb{E}[\\,p(s_t)^\\top \\Sigma\\, p(s_t)\\,]}}.\n  $$\n* **Compute numerator and denominator explicitly**\n\n  $$\n  a^\\top p\n  = a(s_t)^\\top \\big(\\tfrac{1}{\\lambda}\\Sigma^{-1}a(s_t)\\big)\n  = \\frac{1}{\\lambda}\\,a(s_t)^\\top\\Sigma^{-1}a(s_t).\n  $$\n\n  $$\n  p^\\top \\Sigma p\n  = \\big(\\tfrac{1}{\\lambda}\\Sigma^{-1}a(s_t)\\big)^\\top \\Sigma\n    \\big(\\tfrac{1}{\\lambda}\\Sigma^{-1}a(s_t)\\big)\n  = \\frac{1}{\\lambda^2}\\,a(s_t)^\\top\\Sigma^{-1}a(s_t).\n  $$\n* **Cancel the common factor under the ratio**\n\n  $$\n  \\boxed{\\;GIR\n  = \\sqrt{\\;\\mathbb{E}\\!\\left[a(s_t)^\\top\\Sigma^{-1}a(s_t)\\right]\\,}. \\;}\n  $$\n\n---\n\n## 5) Evaluate $\\mathbb{E}[\\,a^\\top \\Sigma^{-1} a\\,]$ (no steps skipped)\n\n* **Substitute $a(s_t)=F\\Psi K s_t$** and $\\Sigma^{-1}=F\\Psi^{-2}F^\\top$:\n\n  $$\n  \\begin{aligned}\n  a^\\top \\Sigma^{-1} a\n  &= (F\\Psi K s_t)^\\top \\,(F\\Psi^{-2}F^\\top)\\,(F\\Psi K s_t) \\\\\n  &\\stackrel{(1)}{=} s_t^\\top K^\\top \\Psi^\\top F^\\top F \\Psi^{-2} F^\\top F \\Psi K s_t \\\\\n  &\\stackrel{(2)}{=} s_t^\\top K^\\top \\Psi \\underbrace{(F^\\top F)}_{I}\\Psi^{-2}\\underbrace{(F^\\top F)}_{I}\\Psi K s_t \\\\\n  &\\stackrel{(3)}{=} s_t^\\top K^\\top \\big(\\Psi\\,\\Psi^{-2}\\,\\Psi\\big) K s_t \\\\\n  &\\stackrel{(4)}{=} s_t^\\top K^\\top K s_t,\n  \\end{aligned}\n  $$\n\n  where:\n\n  * (1) uses $(AB)^\\top=B^\\top A^\\top$ and that $\\Psi=\\Psi^\\top$ (diagonal), hence $(F\\Psi K s)^\\top = s^\\top K^\\top \\Psi F^\\top$.\n  * (2) uses orthogonality $F^\\top F=I$.\n  * (3) groups diagonal matrices; $\\Psi\\Psi^{-2}\\Psi=\\operatorname{diag}(\\psi_n\\cdot\\psi_n^{-2}\\cdot\\psi_n)=I$.\n  * (4) removes the identity factor.\n\n* **Take expectation using $\\mathbb{E}[s_t s_t^\\top]=I_M$**\n\n  $$\n  \\begin{aligned}\n  \\mathbb{E}\\!\\left[s_t^\\top K^\\top K s_t\\right]\n  &= \\operatorname{tr}\\!\\Big(K^\\top K\\,\\mathbb{E}[s_t s_t^\\top]\\Big)\n   \\quad\\big(\\text{identity: } \\mathbb{E}[x^\\top A x]=\\operatorname{tr}(A\\,\\mathbb{E}[xx^\\top])\\big)\\\\\n  &= \\operatorname{tr}\\!\\big(K^\\top K\\cdot I_M\\big)\n   = \\operatorname{tr}(K^\\top K).\n  \\end{aligned}\n  $$\n\n* **Therefore**\n\n  $$\n  \\boxed{\\;GIR\n    = \\sqrt{\\operatorname{tr}(K^\\top K)} \n    = \\|K\\|_F.\\;}\n  $$\n\n  *(Frobenius norm: $\\|K\\|_F^2=\\sum_{n,m}k_{n,m}^2$.)*\n\n\n---\n\n## 6) Interpreting $GIR$ (PC view and signal view)\n\n* **Entrywise (components)**\n\n  $$\n  \\operatorname{tr}(K^\\top K) = \\sum_{n=1}^{N}\\sum_{m=1}^{M} k_{n,m}^2.\n  $$\n\n* **PC aggregation**\n\n  * Define per-PC skill:\n\n    $$\n    \\kappa_n^2 \\;\\equiv\\; \\sum_{m=1}^M k_{n,m}^2,\\qquad\n    \\bar{\\kappa}^2 \\;\\equiv\\; \\frac{1}{N}\\sum_{n=1}^N \\kappa_n^2.\n    $$\n  * Then\n\n    $$\n    GIR^2 = \\sum_{n=1}^N \\kappa_n^2 = N\\,\\bar{\\kappa}^2\n    \\;\\Longrightarrow\\;\n    \\boxed{\\;GIR=\\bar{\\kappa}\\sqrt{N}.\\;}\n    $$\n\n* **Signal aggregation**\n\n  * Eigen-decompose\n\n    $$\n    K^\\top K = E C^2 E^\\top,\\qquad\n    C=\\operatorname{diag}(c_1,\\dots,c_M),\\; E^\\top E=I_M.\n    $$\n  * Then\n\n    $$\n    GIR^2=\\operatorname{tr}(K^\\top K)\n    = \\sum_{m=1}^M c_m^2\n    = M\\,\\bar{c}^2,\\quad\n    \\bar{c}^2 \\equiv \\frac{1}{M}\\sum_{m=1}^M c_m^2,\n    $$\n\n    hence\n\n    $$\n    \\boxed{\\;GIR=\\bar{c}\\sqrt{M}.\\;}\n    $$\n\n* **Sanity checks**\n\n  * $K=0 \\Rightarrow GIR=0$.\n  * Adding a signal with zero loadings (a zero column in $K$) leaves $GIR$ unchanged.\n\n---\n\n## Mini reference: identities used (so no re-deriving needed)\n\n* **Orthogonal similarity inverse:** $(F A F^\\top)^{-1} = F A^{-1} F^\\top$ for $F^\\top F=I$.\n* **Transpose of a product:** $(AB)^\\top = B^\\top A^\\top$.\n* **Trace–quadratic form:** $\\mathbb{E}[x^\\top A x] = \\operatorname{tr}(A\\,\\mathbb{E}[xx^\\top])$.\n* **Diagonal cancellations:** For diagonal $\\Psi\\succ0$, $\\Psi\\Psi^{-2}\\Psi=I$.\n* **Orthogonality:** $F^\\top F = I$.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## 7) Source–Portfolio Representation \n\n### 7.0 Conventions (per-period, standardized)\n\n* **Returns:** $R_t = \\mu + F\\,\\Psi\\,v_t$, with $F^\\top F = I$, $\\Psi=\\mathrm{diag}(\\psi_1,\\dots,\\psi_N)\\succ0$.\n* **Standardized shocks:** $\\mathbb{E}[v_t]=0$, $\\operatorname{Cov}(v_t)=I$.\n* **Signals:** $\\mathbb{E}[s_t]=0$, $\\operatorname{Cov}(s_t)=I$.\n* **Skill matrix:** $K := \\mathbb{E}[v_t s_t^\\top]\\in\\mathbb{R}^{N\\times M}$.\n* **Skill geometry:** **define** the eigensystem\n\n  $$\n  K^\\top K \\;=\\; E\\,C^2\\,E^\\top, \n  \\quad E^\\top E = I_M, \n  \\quad C := \\mathrm{diag}(c_1,\\dots,c_M)\\succeq 0.\n  $$\n\n  Here, **$c_m$** are the **effective skills**.\n\n---\n\n### 7.1 Source portfolios\n\n* **Definition (C51).**\n\n  $$\n  \\boxed{P \\;\\equiv\\; F\\,\\Psi^{-1}\\,K\\,E \\in \\mathbb{R}^{N\\times M}}\n  $$\n\n  * Column $p_m$ is the $m$-th **source portfolio** in asset space.\n    \n* **Explanation of construction:**\n\n  1. $K$ links signals $s_t$ to standardized return shocks $v_t$.\n  2. Multiplying by $E$ rotates the signal space so that sources are orthogonal and aligned with eigenvalues $c_m^2$.\n  3. Multiplying by $\\Psi^{-1}$ and $F$ maps those directions back into **asset space**.\n\n* **Result:** each column $p_m$ of $P$ is a **tradable portfolio** that captures exactly one independent source of information.\n---\n\n### 7.2 Surprise return of source portfolios\n\n* **Goal:** express portfolio returns in terms of $v_t$.\n* Start from $R_t-\\mu = F\\Psi v_t$.\n* Compute (C52):\n\n  $$\n  \\begin{align}\n  P^\\top F\\Psi v_t\n  &= (F\\Psi^{-1} K E)^\\top\\,F\\Psi v_t \n   && \\text{(expand transpose)} \\\\\n  &= E^\\top K^\\top \\Psi^{-1} F^\\top F \\Psi\\, v_t \n   && \\text{(transpose + reassociate)}\\\\\n  &= E^\\top K^\\top \\underbrace{\\Psi^{-1}\\Psi}_{I}\\, v_t \n   && \\text{(orthogonality \\(F^\\top F=I\\))} \\\\\n  &= \\boxed{E^\\top K^\\top v_t}. && \\tag{C52}\n  \\end{align}\n  $$\n\n---\n\n### 7.3 Return variance in the source basis\n\nTwo equivalent routes (both shown).\n\n**Route A (via $\\Sigma$)**\nSince $\\Sigma = F\\Psi^2 F^\\top$:\n\n$$\n\\begin{align}\nP^\\top \\Sigma P\n&= (F\\Psi^{-1} K E)^\\top\\,(F\\Psi^2 F^\\top)\\,(F\\Psi^{-1} K E) \\\\\n&= E^\\top K^\\top \\Psi^{-1} \\underbrace{(F^\\top F)}_{I}\\Psi^2 \\underbrace{(F^\\top F)}_{I}\\Psi^{-1} K E \\\\\n&= E^\\top K^\\top \\underbrace{\\Psi^{-1}\\Psi^2\\Psi^{-1}}_{I} K E \\\\\n&= E^\\top (K^\\top K) E \n = \\boxed{C^2}. \\tag{C53}\n\\end{align}\n$$\n\n**Route B (direct from 7.2)**\nWith $u := P^\\top F\\Psi v_t = E^\\top K^\\top v_t$:\n\n$$\n\\operatorname{Var}(u) \n= E^\\top K^\\top\\,\\underbrace{\\operatorname{Var}(v_t)}_{I}\\,K E\n= E^\\top (K^\\top K) E \n= \\boxed{C^2}.\n$$\n\n**Conclusion:** source-portfolio returns are **uncorrelated**, and $\\operatorname{Var}(p_m^\\top R_t)=c_m^2$.\n\n---\n\n### 7.4 Forecasts for source portfolios\n\n* **Alpha in asset space:** **define**\n\n  $$\n  a(s_t) \\;\\equiv\\; F\\,\\Psi\\,K\\,s_t.\n  $$\n\n* **Project onto the source portfolios** (C54):\n\n  $$\n  \\begin{align}\n  a(s_t)^\\top P\n  &= (F\\Psi K s_t)^\\top (F\\Psi^{-1} K E) \\\\\n  &= s_t^\\top K^\\top \\Psi F^\\top F \\Psi^{-1} K E \\\\\n  &= s_t^\\top K^\\top \\underbrace{\\Psi\\Psi^{-1}}_{I} K E \\\\\n  &= s_t^\\top (K^\\top K) E \\\\\n  &= \\boxed{s_t^\\top E\\,C^2}. \\tag{C54}\n  \\end{align}\n  $$\n\n* **Forecast variance** (C56):\n\n  $$\n  \\begin{align}\n  \\operatorname{Var}\\!\\big(a(s_t)^\\top P\\big)\n  &= \\operatorname{Var}\\!\\big(s_t^\\top E C^2\\big) \\\\\n  &= C^2 \\underbrace{E^\\top \\operatorname{Var}(s_t) E}_{I} C^2 \\\\\n  &= \\boxed{C^4}. \\tag{C56}\n  \\end{align}\n  $$\n\n---\n\n### 7.5 Return–forecast covariance in the source basis\n\n* **Define** vectors:\n\n  $$\n  u \\;\\equiv\\; P^\\top F\\Psi v_t \n  \\;=\\; E^\\top K^\\top v_t, \n  \\qquad\n  w \\;\\equiv\\; P^\\top a(s_t) \n  \\;=\\; E^\\top (K^\\top K) s_t.\n  $$\n* **Compute** (C55):\n\n  $$\n  \\begin{align}\n  \\operatorname{Cov}(u,w)\n  &= \\mathbb{E}[u\\,w^\\top] \n   && \\text{(zero means)} \\\\\n  &= E^\\top K^\\top\\,\\underbrace{\\mathbb{E}[v_t s_t^\\top]}_{K}\\,(K^\\top K) E \\\\\n  &= E^\\top (K^\\top K)\\,(K^\\top K) E \\\\\n  &= E^\\top (K^\\top K)^2 E \n   = \\boxed{C^4}. \\tag{C55}\n  \\end{align}\n  $$\n* **Diagonal:** covariance is diagonal in the source basis.\n\n---\n\n### 7.6 Per-source correlation equals effective skill\n\nFor the $m$-th source portfolio $p_m$:\n\n* $\\operatorname{Var}(\\text{return}_m)=c_m^2$ (from $C^2$),\n* $\\operatorname{Var}(\\text{forecast}_m)=c_m^4$ (from $C^4$),\n* $\\operatorname{Cov}(\\text{return}_m,\\text{forecast}_m)=c_m^4$ (from $C^4$).\n\nHence\n\n$$\n\\boxed{\\ \\operatorname{Corr}\\!\\big(p_m^\\top R_t,\\; a(s_t)^\\top p_m\\big)\n= \\frac{c_m^4}{\\sqrt{c_m^2}\\,\\sqrt{c_m^4}} \n= c_m.\\ }\n$$\n\n**Interpretation:** **$c_m$** is exactly the **return–forecast correlation** of the $m$-th source portfolio.\n\n---\n\n## 7.7 GIR in the source–portfolio basis\n\n* **Fact:** source-portfolio returns and forecasts are mutually **uncorrelated across $m$** (everything is diagonal).\n* **Therefore,** the squared ex-ante Sharpe **adds across sources**:\n\n  $$\n  \\begin{aligned}\n  GIR^2\n  &= \\sum_{m=1}^M \n     \\operatorname{Corr}^2\\!\\big(p_m^\\top R_t,\\; a(s_t)^\\top p_m\\big) \\\\\n  &= \\sum_{m=1}^M c_m^2 \n   = \\operatorname{tr}(K^\\top K).\n  \\end{aligned}\n  $$\n* **Result (C58):**\n\n  $$\n  \\boxed{\\ GIR \\;=\\; \\|K\\|_F \\;=\\; \\sqrt{ \\sum_{m=1}^M c_m^2 } \n  \\;=\\; \\bar{c}\\,\\sqrt{M},\\quad \n  \\bar{c}^2 := \\tfrac{1}{M}\\sum_{m=1}^M c_m^2.\\ }\n  $$\n\n---\n\n## 7.8 Redundancy / rank condition\n\n* **Claim:** $K^\\top K \\succeq 0$ (by construction).\n* **If not full rank:** some $c_m=0$ ⇒ the corresponding source is **redundant** (no contribution to GIR) and can be eliminated without loss.\n\n---\n\n### Quick identity list used (so you never have to rethink)\n\n* **Orthogonality:** $F^\\top F = I$, $E^\\top E = I$.\n* **Similarity inverse:** $(F\\Psi^2 F^\\top)^{-1} = F\\Psi^{-2} F^\\top$.\n* **Transpose of product:** $(AB)^\\top = B^\\top A^\\top$.\n* **Variance under linear map:** $\\operatorname{Var}(A x) = A\\,\\operatorname{Var}(x)\\,A^\\top$.\n* **Trace–quadratic form:** $\\mathbb{E}[x^\\top A x] = \\operatorname{tr}(A\\,\\operatorname{Cov}(x))$.\n* **Diagonal cancellations:** $\\Psi^{-1}\\Psi^2\\Psi^{-1}=I$.\n\n---\n\n**End state:** All steps explicit, “**define**” vs “**equal**” cleanly separated, and the final result\n\n$$\nGIR=\\|K\\|_F=\\bar{c}\\sqrt{M}\n$$\n\nfollows directly in the **source–portfolio** basis with **no time-factor leftovers**.\n","metadata":{}},{"cell_type":"markdown","source":"## 11) The Realized Information Coefficient (IC)\n\nWe want the correlation between realized shocks in returns and forecasts based on signals.\n\n---\n\n### 11.1 General definition\n\n* **Definition (C59):**\n\n  $$\n  IC\\{ {s}, {v}\\} \n  := \\frac{ {v}^\\top K  {s}}\n  {\\sqrt{ {v}^\\top  {v}}\\;\\sqrt{ {s}^\\top (K^\\top K)\\, {s}}}.\n  \\tag{C59}\n  $$\n\n* **Interpretation:**\n  This is the sample correlation between realized standardized shocks $ {v}$ and forecasted components $K {s}$.\n\n---\n\n### 11.2 Approximations (legacy version)\n\nThe original text used crude approximations:\n\n1. For the denominator involving $ {v}^\\top  {v}$:\n\n   $$\n   \\mathbb{E}[ {v}^\\top  {v}] = N \\quad\\Rightarrow\\quad \\sqrt{ {v}^\\top  {v}} \\approx \\sqrt{N}. \n   \\tag{C60'}\n   $$\n  \n\n2. For the numerator involving $ {v}^\\top K  {s}$:\n\n   $$\n   \\begin{align}\n   \\mathbb{E}[ {v}^\\top K  {s}]\n   &= \\operatorname{tr}(K^\\top \\mathbb{E}[ {v} {s}^\\top]) \\\\\n   &= \\operatorname{tr}(K^\\top K) \\\\\n   &= \\kappa^2 N. \\tag{C61'}\n   \\end{align}\n   $$\n\n   where we **define**\n\n   $$\n   \\kappa^2 := \\frac{1}{N}\\,\\operatorname{tr}(K^\\top K).\n   \\tag{C31'}\n   $$\n\n3. For the denominator involving $ {s}^\\top (K^\\top K) {s}$:\n\n   $$\n   \\mathbb{E}[ {s}^\\top (K^\\top K) {s}]\n   = \\operatorname{tr}(K^\\top K)\n   = \\kappa^2 N \\quad\\Rightarrow\\quad\n   \\sqrt{ {s}^\\top (K^\\top K) {s}} \\approx \\kappa \\sqrt{N}.\n   \\tag{C62'}\n   $$\n\n---\n\n### 11.3 Substitution into IC formula\n\n* **Plugging (C60'), (C61'), (C62') into (C59):**\n\n  $$\n  IC\\{ {s}, {v}\\}\n  \\;\\approx\\;\n  \\frac{\\kappa^2 N}{\\sqrt{N}\\,\\kappa \\sqrt{N}}.\n  $$\n\n* Simplify:\n\n  $$\n  IC \\approx \\frac{\\kappa^2 N}{\\kappa N}\n  = \\kappa.\n  \\tag{C63'}\n  $$\n\n---\n\n### 11.4 Clean result\n\n$$\n\\boxed{IC \\;\\approx\\; \\kappa}\n$$\n\n* **Meaning:** The realized information coefficient is approximately equal to the **average per-component skill** $\\kappa$.\n\n\n---\n\n✨ **Interpretation:**\n\n* In practice, the IC measures how well signals predict return shocks.\n* Under this model, IC collapses to the standardized average predictive correlation, $\\kappa$.\n* This ties back neatly to the GIR result:\n\n  $$\n  GIR = \\kappa \\sqrt{N},\n  $$\n\n  where IC is the “per-asset skill,” and GIR multiplies it by diversification breadth.\n","metadata":{}}]}